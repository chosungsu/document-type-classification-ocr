{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "# **üìÑ Document type classification baseline code**\n",
    "## Contents\n",
    "- Prepare Environments\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* Îç∞Ïù¥ÌÑ∞ Î°úÎìúÎ•º ÏúÑÌïú Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏åÎ•º ÎßàÏö¥Ìä∏Ìï©ÎãàÎã§.\n",
    "* ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÑ§ÏπòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21945,
     "status": "ok",
     "timestamp": 1700314517484,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "pUjnEto4gIZm",
    "outputId": "0999f10c-e1ff-428c-995b-481eec8a0b58"
   },
   "outputs": [],
   "source": [
    "# Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏å ÎßàÏö¥Ìä∏, ColabÏùÑ Ïù¥Ïö©ÌïòÏßÄ ÏïäÎäîÎã§Î©¥ Ìå®Ïä§Ìï¥ÎèÑ Îê©ÎãàÎã§.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7640,
     "status": "ok",
     "timestamp": 1700314537985,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "5lFQ-gpjnN_m"
   },
   "outputs": [],
   "source": [
    "# Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏åÏóê ÏóÖÎ°úÎìúÎêú ÎåÄÌöå Îç∞Ïù¥ÌÑ∞Î•º ÏïïÏ∂ï Ìï¥Ï†úÌïòÍ≥† Î°úÏª¨Ïóê Ï†ÄÏû•Ìï©ÎãàÎã§.\n",
    "!tar -xvf drive/MyDrive/datasets_fin.tar > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÑ§ÏπòÌï©ÎãàÎã§.\n",
    "!pip install timm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* ÌïôÏäµ Î∞è Ï∂îÎ°†Ïóê ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º Î°úÎìúÌï©ÎãàÎã§.\n",
    "* ÌïôÏäµ Î∞è Ï∂îÎ°†Ïóê ÌïÑÏöîÌïú Ìï®ÏàòÏôÄ ÌÅ¥ÎûòÏä§Î•º Ï†ïÏùòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import augraphy as ag\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import re \n",
    "from PIL import ImageEnhance, ImageFilter\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "import pytesseract\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏãúÎìúÎ•º Í≥†Ï†ïÌï©ÎãàÎã§.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§Î•º Ï†ïÏùòÌï©ÎãàÎã§.\n",
    "#oversampling -> ÌÅ¥ÎûòÏä§ Îπà 130Í∞ú Ï±ÑÏõåÏÑú 1700Í∞ú : max_oversample Î°ú Î∞∞Ïú® Ï°∞Ï†ï\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None, oversample=False, max_oversample=4, use_ocr=False):\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.oversample = oversample\n",
    "        self.max_oversample = max_oversample\n",
    "        self.use_ocr = use_ocr\n",
    "\n",
    "        # OCR ÎåÄÏÉÅ ÌÅ¥ÎûòÏä§ ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú Î∞è Î≤°ÌÑ∞Ìôî\n",
    "        if self.use_ocr:\n",
    "            ocr_texts = [\n",
    "                extract_text_from_image(os.path.join(self.path, row['ID'])) \n",
    "                if row['target'] in [3, 4, 7, 14] else \"\" \n",
    "                for _, row in self.df.iterrows()\n",
    "            ]\n",
    "            self.text_vectors = text_to_vector(ocr_texts)\n",
    "        else:\n",
    "            self.text_vectors = [np.zeros(50) for _ in range(len(self.df))]  # OCR ÎπÑÌôúÏÑ±Ìôî Ïãú Í∏∞Î≥∏ 0 Î≤°ÌÑ∞ ÏÇ¨Ïö©\n",
    "            \n",
    "        if self.oversample:\n",
    "            self.df, self.text_vectors = self.apply_oversampling(self.df, self.text_vectors)\n",
    "\n",
    "    def apply_oversampling(self, df, text_vectors):\n",
    "        class_counts = Counter(df['target'])\n",
    "        max_count = int(max(class_counts.values()) * self.max_oversample)  # ÏÑ§Ï†ïÌïú Î∞∞ÏàòÎßåÌÅº ÏÉòÌîå Ïàò Ï†úÌïú\n",
    "        oversampled_df = df.copy()\n",
    "        oversampled_text_vectors = text_vectors[:]\n",
    "\n",
    "        for cls, count in class_counts.items():\n",
    "            if count < max_count:\n",
    "                # Î∂ÄÏ°±Ìïú ÏÉòÌîå ÏàòÎßåÌÅº Ï∂îÍ∞Ä Î≥µÏ†ú\n",
    "                samples_to_add = df[df['target'] == cls]\n",
    "                text_vectors_to_add = [text_vectors[i] for i in samples_to_add.index]\n",
    "                \n",
    "                for _ in range(max_count // count - 1):  # Î∞∞ÏàòÎßåÌÅº Ï∂îÍ∞Ä\n",
    "                    oversampled_df = pd.concat([oversampled_df, samples_to_add])\n",
    "                    oversampled_text_vectors.extend(text_vectors_to_add)\n",
    "                \n",
    "                # ÎÇòÎ®∏ÏßÄ Ï∂îÍ∞Ä Î≥µÏ†ú\n",
    "                remainder = max_count % count\n",
    "                if remainder > 0:\n",
    "                    oversampled_df = pd.concat([oversampled_df, samples_to_add.sample(remainder, replace=True)])\n",
    "                    oversampled_text_vectors.extend(text_vectors_to_add[:remainder])\n",
    "\n",
    "        return oversampled_df.sample(frac=1).reset_index(drop=True), oversampled_text_vectors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_name = self.df.iloc[idx]['ID']\n",
    "        target = self.df.iloc[idx]['target']\n",
    "        img_path = os.path.join(self.path, image_name)\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        \n",
    "        # OCR ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        text_vector = self.text_vectors[idx] if self.use_ocr and target in [3, 4, 7, 14] else np.zeros(50)\n",
    "        \n",
    "        return img, torch.tensor(text_vector, dtype=torch.float32), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_for_ocr(img):\n",
    "    # Ïù¥ÎØ∏ÏßÄ ÌôïÎåÄ\n",
    "    img = img.resize((img.width * 2, img.height * 2), Image.LANCZOS)\n",
    "    \n",
    "    # Î∞ùÍ∏∞ Î∞è ÎåÄÎπÑ Ï°∞Ï†à\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(2)  # ÎåÄÎπÑ Ï¶ùÍ∞Ä\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(1.5)  # Î∞ùÍ∏∞ Ï¶ùÍ∞Ä\n",
    "    \n",
    "    # Ïù¥ÎØ∏ÏßÄ ÎÇ†Ïπ¥Î°úÏõÄ Ï¶ùÍ∞Ä\n",
    "    img = img.filter(ImageFilter.SHARPEN)\n",
    "    \n",
    "    # Augraphy Î≥ÄÌòï ÏÑ§Ï†ï Î∞è Ï†ÅÏö©\n",
    "    pipeline = ag.Compose([\n",
    "        ag.DirtyRollers(p=0.5),    # Î®ºÏßÄ Ìö®Í≥º Ï∂îÍ∞Ä\n",
    "        ag.NoiseTexturize(p=0.5),  # ÎÖ∏Ïù¥Ï¶à ÌÖçÏä§Ï≤òÌôî\n",
    "        ag.Brighten(p=0.3, factor=(1.25, 1.5)),  # Î∞ùÍ∏∞ Ï¶ùÍ∞Ä\n",
    "        ag.FoldingEffect(p=0.5, fold_height=(5, 20), fold_width=(5, 15), gradient_width=(0.1, 0.3)),\n",
    "        ag.InkBleed(p=0.3, intensity_range=(0.1, 0.2)),\n",
    "        ag.InkMottling(p=0.3, severity=(0.2, 0.4)),\n",
    "        ag.SubtleNoiseTexturize(p=0.4, sigma=(0.1, 0.3)),\n",
    "        ag.GaussianBlur(p=0.3, sigma=(0.1, 1.5)),\n",
    "        ag.LowInkLine(p=0.4, count_range=(2, 5), use_consistent_lines=False),\n",
    "        ag.Jitter(p=0.3, sigma=(1, 2)),\n",
    "        ag.LightingGradient(p=0.5, transparency=(0.75, 0.85), direction=0.5),\n",
    "        ag.Watermark(p=0.3, text=\"CONFIDENTIAL\", font_size_range=(20, 40), rotation_range=(0, 90))\n",
    "    ])\n",
    "    \n",
    "    # AugraphyÎ°ú Î≥ÄÌòï Ï†ÅÏö©\n",
    "    img = pipeline(img)\n",
    "\n",
    "    # ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ Î∞è Ïù¥ÏßÑÌôî Ï≤òÎ¶¨\n",
    "    img = img.convert('L')  # Í∑∏Î†àÏù¥Ïä§ÏºÄÏùºÎ°ú Î≥ÄÌôò\n",
    "    threshold = 140  # Ïù¥ÏßÑÌôî ÏûÑÍ≥ÑÍ∞í ÏÑ§Ï†ï\n",
    "    img = img.point(lambda p: p > threshold and 255)  # Ïù¥ÏßÑÌôî Ï†ÅÏö©\n",
    "\n",
    "    return img\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    # Ïù¥ÎØ∏ÏßÄ Ïó¥Í∏∞ Î∞è Ï†ÑÏ≤òÎ¶¨\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = preprocess_image_for_ocr(img)  \n",
    "    # OCRÎ°ú ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú (ÌïúÍµ≠Ïñ¥+ÏòÅÏñ¥)\n",
    "    text = pytesseract.image_to_string(img, lang='kor', config='--psm 6')\n",
    "    # ÌäπÏàò Î¨∏Ïûê Ï†úÍ±∞ (ÌïÑÏöîÏóê Îî∞Îùº Ï°∞Ï†ï)\n",
    "    text = re.sub(r'[^Í∞Ä-Ìû£a-zA-Z0-9\\s]', '', text)  \n",
    "    return text.strip()\n",
    "\n",
    "# ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞Ìôî (TF-IDF + Ï∞®Ïõê Ï∂ïÏÜå)\n",
    "def text_to_vector(texts):\n",
    "    vectorizer = TfidfVectorizer(max_features=500)\n",
    "    text_vectors = vectorizer.fit_transform(texts)\n",
    "    svd = TruncatedSVD(n_components=50)  # Ï∞®Ïõê Ï∂ïÏÜå\n",
    "    text_vectors = svd.fit_transform(text_vectors)\n",
    "    return text_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, gamma=2.0, weight=None):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha  # Focal Loss \n",
    "        self.gamma = gamma  # Focal LossÏùò \n",
    "        self.weight = weight  # Cross-Entropy \n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # Cross-Entropy \n",
    "        cross_entropy_loss = F.cross_entropy(outputs, targets, weight=self.weight)\n",
    "\n",
    "        # Focal Loss \n",
    "        ce_loss = F.cross_entropy(outputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)  # ÏòàÏ∏° ÌôïÎ•†\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "        total_loss = self.alpha * focal_loss + (1 - self.alpha) * cross_entropy_loss\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "#Mixed Precision Training\n",
    "\n",
    "scaler = GradScaler()  # Mixed Precision TrainingÏùÑ ÏúÑÌïú Ïä§ÏºÄÏùºÎü¨ Ï¥àÍ∏∞Ìôî\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, text, targets in pbar:\n",
    "        image, text, targets = image.to(device), text.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast():  # Mixed Precision Ï†ÅÏö©\n",
    "            preds = model(image, text)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌÅ¥ÎûòÏä§Î≥Ñ ÏÉòÌîå Ïàò:\n",
      " target\n",
      "16    100\n",
      "10    100\n",
      "0     100\n",
      "3     100\n",
      "12    100\n",
      "8     100\n",
      "2     100\n",
      "11    100\n",
      "7     100\n",
      "9     100\n",
      "15    100\n",
      "5     100\n",
      "4     100\n",
      "6     100\n",
      "13     74\n",
      "14     50\n",
      "1      46\n",
      "Name: count, dtype: int64\n",
      "ÌÅ¥ÎûòÏä§Î≥Ñ ÎπÑÏú®:\n",
      " target\n",
      "16    0.063694\n",
      "10    0.063694\n",
      "0     0.063694\n",
      "3     0.063694\n",
      "12    0.063694\n",
      "8     0.063694\n",
      "2     0.063694\n",
      "11    0.063694\n",
      "7     0.063694\n",
      "9     0.063694\n",
      "15    0.063694\n",
      "5     0.063694\n",
      "4     0.063694\n",
      "6     0.063694\n",
      "13    0.047134\n",
      "14    0.031847\n",
      "1     0.029299\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞\n",
    "data_sample = pd.read_csv(\"/root/data/train.csv\")  # ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ ÌååÏùº\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§ Î∂ÑÌè¨ ÌôïÏù∏\n",
    "class_counts = data_sample['target'].value_counts()\n",
    "print(\"ÌÅ¥ÎûòÏä§Î≥Ñ ÏÉòÌîå Ïàò:\\n\", class_counts)\n",
    "\n",
    "# ÎπÑÏú® Í≥ÑÏÇ∞\n",
    "total_count = len(data_sample)\n",
    "class_ratios = class_counts / total_count\n",
    "print(\"ÌÅ¥ÎûòÏä§Î≥Ñ ÎπÑÏú®:\\n\", class_ratios)\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Class Distribution in Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* ÌïôÏäµ Î∞è Ï∂îÎ°†Ïóê ÌïÑÏöîÌïú ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞Îì§ÏùÑ Ï†ïÏùòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '/root/data'\n",
    "\n",
    "# model config\n",
    "model_name = 'tf_efficientnetv2_m' # 'resnet50' 'efficientnet-b0', ...\n",
    "model_name2 = 'convnext_small'\n",
    "\n",
    "# training config\n",
    "img_size = 288\n",
    "LR = 1e-4\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* ÌïôÏäµ, ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖãÍ≥º Î°úÎçîÎ•º Ï†ïÏùòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§Î≥Ñ Ïù¥ÎØ∏ÏßÄ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞ Ìï®Ïàò\n",
    "def calculate_class_stats(df, img_dir):\n",
    "    class_stats = defaultdict(list)\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_path = f\"{img_dir}/{row['ID']}\"  # Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°ú\n",
    "        target = row['target']  # ÌÅ¥ÎûòÏä§ Î†àÏù¥Î∏î\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # tensor \n",
    "        img_array = np.array(transforms.ToTensor()(img).permute(1, 2, 0))\n",
    "        \n",
    "        # Í∞Å Ï±ÑÎÑêÎ≥Ñ ÌèâÍ∑†Í≥º ÌëúÏ§ÄÌé∏Ï∞® Í≥ÑÏÇ∞\n",
    "        mean = img_array.mean(axis=(0, 1))\n",
    "        std = img_array.std(axis=(0, 1))\n",
    "        \n",
    "        # ÌÅ¥ÎûòÏä§Î≥ÑÎ°ú ÌèâÍ∑†Í≥º ÌëúÏ§ÄÌé∏Ï∞® Ï†ÄÏû•\n",
    "        class_stats[target].append((mean, std))\n",
    "    \n",
    "    # Í∞Å ÌÅ¥ÎûòÏä§Î≥Ñ ÌèâÍ∑†Í≥º ÌëúÏ§ÄÌé∏Ï∞®Ïùò ÌèâÍ∑† Í≥ÑÏÇ∞\n",
    "    class_mean_std = {\n",
    "        cls: (np.mean([s[0] for s in stats], axis=0), np.mean([s[1] for s in stats], axis=0))\n",
    "        for cls, stats in class_stats.items()\n",
    "    }\n",
    "    return class_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1570/1570 [00:28<00:00, 55.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌÅ¥ÎûòÏä§ 16 - Mean: [0.4219013  0.4295417  0.42146945], Std: [0.2373147  0.23417273 0.23942035]\n",
      "ÌÅ¥ÎûòÏä§ 10 - Mean: [0.6575105  0.66326165 0.6644608 ], Std: [0.13163847 0.12877204 0.12457712]\n",
      "ÌÅ¥ÎûòÏä§ 4 - Mean: [0.6555603  0.66125077 0.66331756], Std: [0.15522847 0.15262605 0.14899264]\n",
      "ÌÅ¥ÎûòÏä§ 5 - Mean: [0.4437757  0.45977414 0.46266812], Std: [0.3156187  0.3196577  0.31643304]\n",
      "ÌÅ¥ÎûòÏä§ 15 - Mean: [0.6350243  0.64473253 0.6507628 ], Std: [0.1678749  0.16353387 0.15797006]\n",
      "ÌÅ¥ÎûòÏä§ 14 - Mean: [0.6480721  0.6549895  0.65739745], Std: [0.13476998 0.13317542 0.13080387]\n",
      "ÌÅ¥ÎûòÏä§ 9 - Mean: [0.5308454  0.5393029  0.54112315], Std: [0.3078833  0.30661288 0.3008869 ]\n",
      "ÌÅ¥ÎûòÏä§ 13 - Mean: [0.6464133 0.6576297 0.6628065], Std: [0.16119514 0.1606536  0.1597504 ]\n",
      "ÌÅ¥ÎûòÏä§ 7 - Mean: [0.63879293 0.6516734  0.6549295 ], Std: [0.14560634 0.14385152 0.14064762]\n",
      "ÌÅ¥ÎûòÏä§ 11 - Mean: [0.5965798  0.61167085 0.6179784 ], Std: [0.18097693 0.17057073 0.17047977]\n",
      "ÌÅ¥ÎûòÏä§ 2 - Mean: [0.29230753 0.26621136 0.2712087 ], Std: [0.19488445 0.18460369 0.18703903]\n",
      "ÌÅ¥ÎûòÏä§ 8 - Mean: [0.4591894  0.48785004 0.5136458 ], Std: [0.2949226  0.30572063 0.31396866]\n",
      "ÌÅ¥ÎûòÏä§ 12 - Mean: [0.6531739  0.6636219  0.66996545], Std: [0.13231365 0.12964574 0.1266244 ]\n",
      "ÌÅ¥ÎûòÏä§ 3 - Mean: [0.65375656 0.6593415  0.6593775 ], Std: [0.14589216 0.14422888 0.14131746]\n",
      "ÌÅ¥ÎûòÏä§ 0 - Mean: [0.5997213  0.61057276 0.6175231 ], Std: [0.151559   0.149929   0.14750864]\n",
      "ÌÅ¥ÎûòÏä§ 1 - Mean: [0.6672302 0.6775926 0.6834501], Std: [0.14367767 0.14226489 0.13918385]\n",
      "ÌÅ¥ÎûòÏä§ 6 - Mean: [0.6696616  0.6832548  0.69261336], Std: [0.1630469  0.150923   0.14306074]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/root/data/train.csv\")  # ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Î∂àÎü¨Ïò§Í∏∞\n",
    "img_dir = \"/root/data/train\"  # Ïù¥ÎØ∏ÏßÄ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°ú\n",
    "class_mean_std = calculate_class_stats(df, img_dir)\n",
    "\n",
    "# Í∞Å ÌÅ¥ÎûòÏä§Ïùò ÌèâÍ∑†Í≥º ÌëúÏ§ÄÌé∏Ï∞® Ï∂úÎ†•\n",
    "for cls, (mean, std) in class_mean_std.items():\n",
    "    print(f\"ÌÅ¥ÎûòÏä§ {cls} - Mean: {mean}, Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58055977, 0.58954542, 0.59439398]),\n",
       " array([0.18614137, 0.18358485, 0.18168615]))"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ÌÅ¥ÎûòÏä§Î≥Ñ ÌèâÍ∑†(mean)Í≥º ÌëúÏ§ÄÌé∏Ï∞®(std) Í∞í Ï†ÄÏû•\n",
    "means = np.array([\n",
    "    [0.4219013, 0.4295417, 0.42146945],\n",
    "    [0.6575105, 0.66326165, 0.6644608],\n",
    "    [0.6555603, 0.66125077, 0.66331756],\n",
    "    [0.4437757, 0.45977414, 0.46266812],\n",
    "    [0.6350243, 0.64473253, 0.6507628],\n",
    "    [0.6480721, 0.6549895, 0.65739745],\n",
    "    [0.5308454, 0.5393029, 0.54112315],\n",
    "    [0.6464133, 0.6576297, 0.6628065],\n",
    "    [0.63879293, 0.6516734, 0.6549295],\n",
    "    [0.5965798, 0.61167085, 0.6179784],\n",
    "    [0.29230753, 0.26621136, 0.2712087],\n",
    "    [0.4591894, 0.48785004, 0.5136458],\n",
    "    [0.6531739, 0.6636219, 0.66996545],\n",
    "    [0.65375656, 0.6593415, 0.6593775],\n",
    "    [0.5997213, 0.61057276, 0.6175231],\n",
    "    [0.6672302, 0.6775926, 0.6834501],\n",
    "    [0.6696616, 0.6832548, 0.69261336]\n",
    "])\n",
    "\n",
    "stds = np.array([\n",
    "    [0.2373147, 0.23417273, 0.23942035],\n",
    "    [0.13163847, 0.12877204, 0.12457712],\n",
    "    [0.15522847, 0.15262605, 0.14899264],\n",
    "    [0.3156187, 0.3196577, 0.31643304],\n",
    "    [0.1678749, 0.16353387, 0.15797006],\n",
    "    [0.13476998, 0.13317542, 0.13080387],\n",
    "    [0.3078833, 0.30661288, 0.3008869],\n",
    "    [0.16119514, 0.1606536, 0.1597504],\n",
    "    [0.14560634, 0.14385152, 0.14064762],\n",
    "    [0.18097693, 0.17057073, 0.17047977],\n",
    "    [0.19488445, 0.18460369, 0.18703903],\n",
    "    [0.2949226, 0.30572063, 0.31396866],\n",
    "    [0.13231365, 0.12964574, 0.1266244],\n",
    "    [0.14589216, 0.14422888, 0.14131746],\n",
    "    [0.151559, 0.149929, 0.14750864],\n",
    "    [0.14367767, 0.14226489, 0.13918385],\n",
    "    [0.1630469, 0.150923, 0.14306074]\n",
    "])\n",
    "\n",
    "# Ï†ÑÏ≤¥ ÌèâÍ∑†(mean)Í≥º ÌëúÏ§ÄÌé∏Ï∞®(std)Î•º Í≥ÑÏÇ∞\n",
    "overall_mean = means.mean(axis=0)\n",
    "overall_std = stds.mean(axis=0)\n",
    "\n",
    "overall_mean, overall_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [],
   "source": [
    "# ÌõàÎ†® Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú Transform ÏΩîÎìú\n",
    "\n",
    "trn_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.RandomResizedCrop(height=img_size, width=img_size, scale=(0.8, 1.2), ratio=(0.75, 1.33), p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=(-40,40), p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.RandomGamma(p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, min_holes=1, fill_value=0, p=0.5),\n",
    "    A.MotionBlur(blur_limit=5, p=0.2),\n",
    "    A.GaussianBlur(blur_limit=(3,7), p=0.2),\n",
    "    A.GaussNoise(always_apply=False, var_limit=(50.0, 200.0), p=0.5, per_channel=True, mean= 0.0),\n",
    "    A.Affine(shear=15, rotate=10, scale=(0.9, 1.1), p=0.5),\n",
    "    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n",
    "    A.GridDistortion(p=0.3),\n",
    "    A.ImageCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3), \n",
    "    \n",
    "    # Ï∂îÍ∞Ä \n",
    "    A.GridDropout(ratio=0.5, holes_number_x=3, holes_number_y=3, p=0.3),  # GridMask\n",
    "    A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.3),\n",
    "    A.ChannelShuffle(p=0.1),\n",
    "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, p=0.2),\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.2),  # Ïù¥ÎØ∏ÏßÄ ÏÑ†Î™ÖÌôî Ï∂îÍ∞Ä\n",
    "    A.Normalize(mean=[0.5805, 0.5895, 0.5944], std=[0.186, 0.183, 0.187]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú Transform ÏΩîÎìú\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.5805, 0.5895, 0.5944], std=[0.186, 0.183, 0.187]),\n",
    "    ToTensorV2(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "INxdmsStop2L",
    "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800 3140\n"
     ]
    }
   ],
   "source": [
    "# Dataset Ï†ïÏùò\n",
    "trn_dataset = ImageDataset(\n",
    "    \"/root/data/train.csv\",\n",
    "    \"/root/data/train/\",\n",
    "    transform=trn_transform,\n",
    "    oversample=True\n",
    ")\n",
    "tst_dataset = ImageDataset(\n",
    "    \"/root/data/sample_submission.csv\",\n",
    "    \"/root/data/test/\",\n",
    "    transform=tst_transform\n",
    ")\n",
    "print(len(trn_dataset), len(tst_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "_sO03fWaQj1h"
   },
   "outputs": [],
   "source": [
    "# DataLoader Ï†ïÏùò\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "    drop_last=False\n",
    ")\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* Î™®Îç∏ÏùÑ Î°úÎìúÌïòÍ≥†, ÌïôÏäµÏùÑ ÏßÑÌñâÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['efficientnet_b0', 'efficientnet_b0_g8_gn', 'efficientnet_b0_g16_evos', 'efficientnet_b0_gn', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b3', 'efficientnet_b3_g8_gn', 'efficientnet_b3_gn', 'efficientnet_b3_pruned', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_b8', 'efficientnet_cc_b0_4e', 'efficientnet_cc_b0_8e', 'efficientnet_cc_b1_8e', 'efficientnet_el', 'efficientnet_el_pruned', 'efficientnet_em', 'efficientnet_es', 'efficientnet_es_pruned', 'efficientnet_l2', 'efficientnet_lite0', 'efficientnet_lite1', 'efficientnet_lite2', 'efficientnet_lite3', 'efficientnet_lite4', 'efficientnetv2_l', 'efficientnetv2_m', 'efficientnetv2_rw_m', 'efficientnetv2_rw_s', 'efficientnetv2_rw_t', 'efficientnetv2_s', 'efficientnetv2_xl', 'gc_efficientnetv2_rw_t', 'tf_efficientnet_b0', 'tf_efficientnet_b1', 'tf_efficientnet_b2', 'tf_efficientnet_b3', 'tf_efficientnet_b4', 'tf_efficientnet_b5', 'tf_efficientnet_b6', 'tf_efficientnet_b7', 'tf_efficientnet_b8', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_efficientnetv2_b0', 'tf_efficientnetv2_b1', 'tf_efficientnetv2_b2', 'tf_efficientnetv2_b3', 'tf_efficientnetv2_l', 'tf_efficientnetv2_m', 'tf_efficientnetv2_s', 'tf_efficientnetv2_xl']\n"
     ]
    }
   ],
   "source": [
    "print(timm.list_models(\"*efficientnet*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, model_name, text_dim=50, num_classes=17, text_weight=1.5):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "        self.image_model = timm.create_model(model_name, pretrained=True, num_classes=0)  # ÏµúÏ¢Ö Î∂ÑÎ•ò Î†àÏù¥Ïñ¥ Ï†úÍ±∞\n",
    "        self.text_fc = nn.Linear(text_dim, 256)  # ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞Î•º ÏúÑÌïú Ï∂îÍ∞Ä Î†àÏù¥Ïñ¥\n",
    "        self.classifier = nn.Linear(256 + self.image_model.num_features, num_classes)  # Ïù¥ÎØ∏ÏßÄÏôÄ ÌÖçÏä§Ìä∏ ÌäπÏßï Í≤∞Ìï©\n",
    "        self.text_weight = text_weight\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        img_features = self.image_model(image)\n",
    "        text_features = self.text_fc(text)\n",
    "        \n",
    "        # Ïù¥ÎØ∏ÏßÄÏôÄ ÌÖçÏä§Ìä∏ ÌäπÏßïÏùÑ Í≤∞Ìï©ÌïòÏó¨ ÏµúÏ¢Ö Î∂ÑÎ•ò Î†àÏù¥Ïñ¥Ïóê Ï†ÑÎã¨\n",
    "        combined_features = torch.cat([img_features, text_features], dim=1)\n",
    "        return self.classifier(combined_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class MultimodalModel2(nn.Module):\n",
    "    def __init__(self, model_name2, text_dim=50, num_classes=17, text_weight=1.5):\n",
    "        super(MultimodalModel2, self).__init__()\n",
    "        self.image_model = timm.create_model(model_name2, pretrained=True, num_classes=0)  # ÏµúÏ¢Ö Î∂ÑÎ•ò Î†àÏù¥Ïñ¥ Ï†úÍ±∞\n",
    "        self.text_fc = nn.Linear(text_dim, 256)  # ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞Î•º ÏúÑÌïú Ï∂îÍ∞Ä Î†àÏù¥Ïñ¥\n",
    "        self.classifier = nn.Linear(256 + self.image_model.num_features, num_classes)  # Ïù¥ÎØ∏ÏßÄÏôÄ ÌÖçÏä§Ìä∏ ÌäπÏßï Í≤∞Ìï©\n",
    "        self.text_weight = text_weight\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        img_features = self.image_model(image)\n",
    "        text_features = self.text_fc(text)\n",
    "        \n",
    "        # Ïù¥ÎØ∏ÏßÄÏôÄ ÌÖçÏä§Ìä∏ ÌäπÏßïÏùÑ Í≤∞Ìï©ÌïòÏó¨ ÏµúÏ¢Ö Î∂ÑÎ•ò Î†àÏù¥Ïñ¥Ïóê Ï†ÑÎã¨\n",
    "        combined_features = torch.cat([img_features, text_features], dim=1)\n",
    "        return self.classifier(combined_features)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1700315114067,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "FbBgFPsLT-CO"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "#loss_fn = FocalLoss(alpha=1, gamma=2)\n",
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([1.0] * 17).to(device) \n",
    "class_weights[[3, 4, 7, 14]] *= 2 \n",
    "\n",
    "model = MultimodalModel(\n",
    "    model_name=model_name,\n",
    "    text_dim=50,  # ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞Ïùò Ï∞®Ïõê\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "\n",
    "#loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1,weight=class_weights)\n",
    "loss_fn = CombinedLoss(alpha=0.5, gamma=2.0, weight=class_weights).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class_weights = torch.tensor([1.0] * 17).to(device) \n",
    "class_weights[[3, 4, 7, 14]] *= 2 \n",
    "\n",
    "model2 = MultimodalModel(\n",
    "    model_name=model_name2,\n",
    "    text_dim=50,  # ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞Ïùò Ï∞®Ïõê\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "\n",
    "#loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1,weight=class_weights)\n",
    "loss_fn = CombinedLoss(alpha=0.5, gamma=2.0, weight=class_weights).to(device)\n",
    "optimizer = AdamW(model2.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8778,
     "status": "ok",
     "timestamp": 1700315122843,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "OvIVcSRgUPtS",
    "outputId": "88230bf2-976f-45f6-b3b7-1a2d0ad00548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.9963\n",
      "Train F1 Score: 0.6705\n",
      "\n",
      "Epoch 2\n",
      "Train Loss: 0.3231\n",
      "Train F1 Score: 0.8830\n",
      "\n",
      "Epoch 3\n",
      "Train Loss: 0.2142\n",
      "Train F1 Score: 0.9161\n",
      "\n",
      "Epoch 4\n",
      "Train Loss: 0.1669\n",
      "Train F1 Score: 0.9380\n",
      "\n",
      "Epoch 5\n",
      "Train Loss: 0.1407\n",
      "Train F1 Score: 0.9459\n",
      "\n",
      "Epoch 6\n",
      "Train Loss: 0.1242\n",
      "Train F1 Score: 0.9527\n",
      "\n",
      "Epoch 7\n",
      "Train Loss: 0.1002\n",
      "Train F1 Score: 0.9647\n",
      "\n",
      "Epoch 8\n",
      "Train Loss: 0.0956\n",
      "Train F1 Score: 0.9653\n",
      "\n",
      "Epoch 9\n",
      "Train Loss: 0.0836\n",
      "Train F1 Score: 0.9690\n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.0772\n",
      "Train F1 Score: 0.9731\n",
      "\n",
      "Epoch 11\n",
      "Train Loss: 0.0757\n",
      "Train F1 Score: 0.9728\n",
      "\n",
      "Epoch 12\n",
      "Train Loss: 0.0616\n",
      "Train F1 Score: 0.9777\n",
      "\n",
      "Epoch 13\n",
      "Train Loss: 0.0679\n",
      "Train F1 Score: 0.9755\n",
      "\n",
      "Epoch 14\n",
      "Train Loss: 0.0599\n",
      "Train F1 Score: 0.9796\n",
      "\n",
      "Epoch 15\n",
      "Train Loss: 0.0512\n",
      "Train F1 Score: 0.9813\n",
      "\n",
      "Epoch 16\n",
      "Train Loss: 0.0497\n",
      "Train F1 Score: 0.9825\n",
      "\n",
      "Epoch 17\n",
      "Train Loss: 0.0509\n",
      "Train F1 Score: 0.9820\n",
      "\n",
      "Epoch 18\n",
      "Train Loss: 0.0475\n",
      "Train F1 Score: 0.9830\n",
      "\n",
      "Epoch 19\n",
      "Train Loss: 0.0463\n",
      "Train F1 Score: 0.9824\n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.0450\n",
      "Train F1 Score: 0.9850\n",
      "\n",
      "Epoch 21\n",
      "Train Loss: 0.0388\n",
      "Train F1 Score: 0.9850\n",
      "\n",
      "Epoch 22\n",
      "Train Loss: 0.0500\n",
      "Train F1 Score: 0.9837\n",
      "\n",
      "Epoch 23\n",
      "Train Loss: 0.0334\n",
      "Train F1 Score: 0.9884\n",
      "\n",
      "Epoch 24\n",
      "Train Loss: 0.0400\n",
      "Train F1 Score: 0.9851\n",
      "\n",
      "Epoch 25\n",
      "Train Loss: 0.0348\n",
      "Train F1 Score: 0.9882\n",
      "\n",
      "Epoch 00026: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 26\n",
      "Train Loss: 0.0461\n",
      "Train F1 Score: 0.9844\n",
      "\n",
      "Epoch 27\n",
      "Train Loss: 0.0284\n",
      "Train F1 Score: 0.9910\n",
      "\n",
      "Epoch 28\n",
      "Train Loss: 0.0192\n",
      "Train F1 Score: 0.9928\n",
      "\n",
      "Epoch 29\n",
      "Train Loss: 0.0190\n",
      "Train F1 Score: 0.9921\n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.0187\n",
      "Train F1 Score: 0.9934\n",
      "\n",
      "Epoch 31\n",
      "Train Loss: 0.0191\n",
      "Train F1 Score: 0.9926\n",
      "\n",
      "Epoch 32\n",
      "Train Loss: 0.0187\n",
      "Train F1 Score: 0.9935\n",
      "\n",
      "Epoch 33\n",
      "Train Loss: 0.0179\n",
      "Train F1 Score: 0.9947\n",
      "\n",
      "Epoch 34\n",
      "Train Loss: 0.0198\n",
      "Train F1 Score: 0.9929\n",
      "\n",
      "Epoch 35\n",
      "Train Loss: 0.0192\n",
      "Train F1 Score: 0.9929\n",
      "\n",
      "Epoch 00036: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 36\n",
      "Train Loss: 0.0130\n",
      "Train F1 Score: 0.9946\n",
      "\n",
      "Epoch 37\n",
      "Train Loss: 0.0116\n",
      "Train F1 Score: 0.9962\n",
      "\n",
      "Epoch 38\n",
      "Train Loss: 0.0152\n",
      "Train F1 Score: 0.9954\n",
      "\n",
      "Epoch 39\n",
      "Train Loss: 0.0108\n",
      "Train F1 Score: 0.9965\n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.0105\n",
      "Train F1 Score: 0.9971\n",
      "\n",
      "Epoch 41\n",
      "Train Loss: 0.0124\n",
      "Train F1 Score: 0.9957\n",
      "\n",
      "Epoch 42\n",
      "Train Loss: 0.0078\n",
      "Train F1 Score: 0.9971\n",
      "\n",
      "Epoch 00043: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Epoch 43\n",
      "Train Loss: 0.0095\n",
      "Train F1 Score: 0.9969\n",
      "\n",
      "Epoch 44\n",
      "Train Loss: 0.0073\n",
      "Train F1 Score: 0.9971\n",
      "\n",
      "Epoch 45\n",
      "Train Loss: 0.0078\n",
      "Train F1 Score: 0.9972\n",
      "\n",
      "Epoch 46\n",
      "Train Loss: 0.0110\n",
      "Train F1 Score: 0.9966\n",
      "\n",
      "Epoch 47\n",
      "Train Loss: 0.0103\n",
      "Train F1 Score: 0.9966\n",
      "\n",
      "Epoch 48\n",
      "Train Loss: 0.0065\n",
      "Train F1 Score: 0.9984\n",
      "\n",
      "Epoch 49\n",
      "Train Loss: 0.0098\n",
      "Train F1 Score: 0.9972\n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.0063\n",
      "Train F1 Score: 0.9975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# Ï°∞Í∏∞ Ï¢ÖÎ£å ÏÑ§Ï†ï\n",
    "patience = 5  # Í∞úÏÑ†ÎêòÏßÄ ÏïäÎäî ÏóêÌè¨ÌÅ¨ Ïàò\n",
    "best_f1 = 0   # ÏµúÍ≥† F1 Ïä§ÏΩîÏñ¥\n",
    "early_stopping_counter = 0  # Ï°∞Í∏∞ Ï¢ÖÎ£å Ïπ¥Ïö¥ÌÑ∞\n",
    "\n",
    "# ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "#scheduler = OneCycleLR(optimizer, max_lr=LR, steps_per_epoch=len(trn_loader), epochs=EPOCHS)\n",
    "\n",
    "# ÌïôÏäµ Î£®ÌîÑ\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    text_weight = 1.5  # ÌäπÏ†ï ÌÅ¥ÎûòÏä§ÏóêÏÑú ÌÖçÏä§Ìä∏ ÎπÑÏ§ëÏùÑ ÎÜíÏù¥Îäî Í∞í\n",
    "\n",
    "    for images, text_vectors, targets in trn_loader:\n",
    "        images, text_vectors, targets = images.to(device), text_vectors.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ÌäπÏ†ï ÌÅ¥ÎûòÏä§Ïùò Í≤ΩÏö∞ ÌÖçÏä§Ìä∏ ÎπÑÏ§ëÏùÑ ÎÜíÏûÑ\n",
    "        mask = torch.isin(targets, torch.tensor([3, 4, 7, 14], device=device))\n",
    "        text_vectors = torch.where(mask.unsqueeze(1), text_vectors * text_weight, text_vectors)\n",
    "\n",
    "        # Î™®Îç∏Ïóê Ïù¥ÎØ∏ÏßÄÏôÄ ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞Î•º Ï†ÑÎã¨\n",
    "        outputs = model(images, text_vectors)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    train_loss /= len(trn_loader)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    # Scheduler stepÏùÑ F1 Ïä§ÏΩîÏñ¥ Í∏∞Ï§ÄÏúºÎ°ú Ï°∞Ï†ï\n",
    "    scheduler.step(train_f1)\n",
    "\n",
    "    # F1 Ïä§ÏΩîÏñ¥ Í∞úÏÑ† ÌôïÏù∏\n",
    "    if train_f1 > best_f1:\n",
    "        best_f1 = train_f1  # ÏµúÍ≥† F1 Í∞±Ïã†\n",
    "        early_stopping_counter = 0  # Ïπ¥Ïö¥ÌÑ∞ Ï¥àÍ∏∞Ìôî\n",
    "    else:\n",
    "        early_stopping_counter += 1  # Í∞úÏÑ†ÎêòÏßÄ ÏïäÏúºÎ©¥ Ïπ¥Ïö¥ÌÑ∞ Ï¶ùÍ∞Ä\n",
    "\n",
    "    # Ï°∞Í∏∞ Ï¢ÖÎ£å Ï°∞Í±¥ ÌôïÏù∏\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(\"Early stopping due to no improvement in F1 score.\")\n",
    "        break  # ÌïôÏäµ Ï§ëÎã®\n",
    "\n",
    "    # Î°úÍ∑∏ Ï∂úÎ†•\n",
    "    log = f\"Epoch {epoch + 1}\\nTrain Loss: {train_loss:.4f}\\nTrain F1 Score: {train_f1:.4f}\\n\"\n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.9385\n",
      "Train F1 Score: 0.6477\n",
      "\n",
      "Epoch 2\n",
      "Train Loss: 0.3658\n",
      "Train F1 Score: 0.8581\n",
      "\n",
      "Epoch 3\n",
      "Train Loss: 0.2726\n",
      "Train F1 Score: 0.8919\n",
      "\n",
      "Epoch 4\n",
      "Train Loss: 0.2088\n",
      "Train F1 Score: 0.9149\n",
      "\n",
      "Epoch 5\n",
      "Train Loss: 0.1830\n",
      "Train F1 Score: 0.9271\n",
      "\n",
      "Epoch 6\n",
      "Train Loss: 0.1642\n",
      "Train F1 Score: 0.9368\n",
      "\n",
      "Epoch 7\n",
      "Train Loss: 0.1547\n",
      "Train F1 Score: 0.9386\n",
      "\n",
      "Epoch 8\n",
      "Train Loss: 0.1537\n",
      "Train F1 Score: 0.9432\n",
      "\n",
      "Epoch 9\n",
      "Train Loss: 0.1369\n",
      "Train F1 Score: 0.9476\n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.1174\n",
      "Train F1 Score: 0.9558\n",
      "\n",
      "Epoch 11\n",
      "Train Loss: 0.1184\n",
      "Train F1 Score: 0.9549\n",
      "\n",
      "Epoch 12\n",
      "Train Loss: 0.0969\n",
      "Train F1 Score: 0.9612\n",
      "\n",
      "Epoch 13\n",
      "Train Loss: 0.0973\n",
      "Train F1 Score: 0.9651\n",
      "\n",
      "Epoch 14\n",
      "Train Loss: 0.0895\n",
      "Train F1 Score: 0.9665\n",
      "\n",
      "Epoch 15\n",
      "Train Loss: 0.0892\n",
      "Train F1 Score: 0.9663\n",
      "\n",
      "Epoch 16\n",
      "Train Loss: 0.0960\n",
      "Train F1 Score: 0.9626\n",
      "\n",
      "Epoch 17\n",
      "Train Loss: 0.0774\n",
      "Train F1 Score: 0.9710\n",
      "\n",
      "Epoch 18\n",
      "Train Loss: 0.0824\n",
      "Train F1 Score: 0.9695\n",
      "\n",
      "Epoch 19\n",
      "Train Loss: 0.0727\n",
      "Train F1 Score: 0.9734\n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.0612\n",
      "Train F1 Score: 0.9777\n",
      "\n",
      "Epoch 21\n",
      "Train Loss: 0.0805\n",
      "Train F1 Score: 0.9678\n",
      "\n",
      "Epoch 22\n",
      "Train Loss: 0.0731\n",
      "Train F1 Score: 0.9736\n",
      "\n",
      "Epoch 00023: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 23\n",
      "Train Loss: 0.0666\n",
      "Train F1 Score: 0.9757\n",
      "\n",
      "Epoch 24\n",
      "Train Loss: 0.0444\n",
      "Train F1 Score: 0.9827\n",
      "\n",
      "Epoch 25\n",
      "Train Loss: 0.0341\n",
      "Train F1 Score: 0.9874\n",
      "\n",
      "Epoch 26\n",
      "Train Loss: 0.0259\n",
      "Train F1 Score: 0.9900\n",
      "\n",
      "Epoch 27\n",
      "Train Loss: 0.0295\n",
      "Train F1 Score: 0.9890\n",
      "\n",
      "Epoch 28\n",
      "Train Loss: 0.0306\n",
      "Train F1 Score: 0.9896\n",
      "\n",
      "Epoch 29\n",
      "Train Loss: 0.0277\n",
      "Train F1 Score: 0.9906\n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.0249\n",
      "Train F1 Score: 0.9907\n",
      "\n",
      "Epoch 31\n",
      "Train Loss: 0.0323\n",
      "Train F1 Score: 0.9884\n",
      "\n",
      "Epoch 32\n",
      "Train Loss: 0.0314\n",
      "Train F1 Score: 0.9894\n",
      "\n",
      "Epoch 00033: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 33\n",
      "Train Loss: 0.0308\n",
      "Train F1 Score: 0.9882\n",
      "\n",
      "Epoch 34\n",
      "Train Loss: 0.0177\n",
      "Train F1 Score: 0.9931\n",
      "\n",
      "Epoch 35\n",
      "Train Loss: 0.0162\n",
      "Train F1 Score: 0.9941\n",
      "\n",
      "Epoch 36\n",
      "Train Loss: 0.0127\n",
      "Train F1 Score: 0.9953\n",
      "\n",
      "Epoch 37\n",
      "Train Loss: 0.0161\n",
      "Train F1 Score: 0.9940\n",
      "\n",
      "Epoch 38\n",
      "Train Loss: 0.0159\n",
      "Train F1 Score: 0.9941\n",
      "\n",
      "Epoch 00039: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Epoch 39\n",
      "Train Loss: 0.0156\n",
      "Train F1 Score: 0.9926\n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.0103\n",
      "Train F1 Score: 0.9957\n",
      "\n",
      "Epoch 41\n",
      "Train Loss: 0.0111\n",
      "Train F1 Score: 0.9957\n",
      "\n",
      "Epoch 42\n",
      "Train Loss: 0.0112\n",
      "Train F1 Score: 0.9954\n",
      "\n",
      "Epoch 43\n",
      "Train Loss: 0.0101\n",
      "Train F1 Score: 0.9963\n",
      "\n",
      "Epoch 44\n",
      "Train Loss: 0.0105\n",
      "Train F1 Score: 0.9960\n",
      "\n",
      "Epoch 45\n",
      "Train Loss: 0.0123\n",
      "Train F1 Score: 0.9962\n",
      "\n",
      "Epoch 00046: reducing learning rate of group 0 to 6.2500e-06.\n",
      "Epoch 46\n",
      "Train Loss: 0.0124\n",
      "Train F1 Score: 0.9957\n",
      "\n",
      "Epoch 47\n",
      "Train Loss: 0.0073\n",
      "Train F1 Score: 0.9965\n",
      "\n",
      "Epoch 48\n",
      "Train Loss: 0.0089\n",
      "Train F1 Score: 0.9966\n",
      "\n",
      "Epoch 49\n",
      "Train Loss: 0.0087\n",
      "Train F1 Score: 0.9960\n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.0073\n",
      "Train F1 Score: 0.9972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Ï°∞Í∏∞ Ï¢ÖÎ£å ÏÑ§Ï†ï\n",
    "patience = 5  # Í∞úÏÑ†ÎêòÏßÄ ÏïäÎäî ÏóêÌè¨ÌÅ¨ Ïàò\n",
    "best_f1 = 0   # ÏµúÍ≥† F1 Ïä§ÏΩîÏñ¥\n",
    "early_stopping_counter = 0  # Ï°∞Í∏∞ Ï¢ÖÎ£å Ïπ¥Ïö¥ÌÑ∞\n",
    "\n",
    "# ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "#scheduler = OneCycleLR(optimizer, max_lr=LR, steps_per_epoch=len(trn_loader), epochs=EPOCHS)\n",
    "\n",
    "# ÌïôÏäµ Î£®ÌîÑ\n",
    "for epoch in range(EPOCHS):\n",
    "    model2.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    text_weight = 1.5  # ÌäπÏ†ï ÌÅ¥ÎûòÏä§ÏóêÏÑú ÌÖçÏä§Ìä∏ ÎπÑÏ§ëÏùÑ ÎÜíÏù¥Îäî Í∞í\n",
    "\n",
    "    for images, text_vectors, targets in trn_loader:\n",
    "        images, text_vectors, targets = images.to(device), text_vectors.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ÌäπÏ†ï ÌÅ¥ÎûòÏä§Ïùò Í≤ΩÏö∞ ÌÖçÏä§Ìä∏ ÎπÑÏ§ëÏùÑ ÎÜíÏûÑ\n",
    "        mask = torch.isin(targets, torch.tensor([3, 4, 7, 14], device=device))\n",
    "        text_vectors = torch.where(mask.unsqueeze(1), text_vectors * text_weight, text_vectors)\n",
    "\n",
    "        # Î™®Îç∏Ïóê Ïù¥ÎØ∏ÏßÄÏôÄ ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞Î•º Ï†ÑÎã¨\n",
    "        outputs = model2(images, text_vectors)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    train_loss /= len(trn_loader)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    # Scheduler stepÏùÑ F1 Ïä§ÏΩîÏñ¥ Í∏∞Ï§ÄÏúºÎ°ú Ï°∞Ï†ï\n",
    "    scheduler.step(train_f1)\n",
    "\n",
    "    # F1 Ïä§ÏΩîÏñ¥ Í∞úÏÑ† ÌôïÏù∏\n",
    "    if train_f1 > best_f1:\n",
    "        best_f1 = train_f1  # ÏµúÍ≥† F1 Í∞±Ïã†\n",
    "        early_stopping_counter = 0  # Ïπ¥Ïö¥ÌÑ∞ Ï¥àÍ∏∞Ìôî\n",
    "    else:\n",
    "        early_stopping_counter += 1  # Í∞úÏÑ†ÎêòÏßÄ ÏïäÏúºÎ©¥ Ïπ¥Ïö¥ÌÑ∞ Ï¶ùÍ∞Ä\n",
    "\n",
    "    # Ï°∞Í∏∞ Ï¢ÖÎ£å Ï°∞Í±¥ ÌôïÏù∏\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(\"Early stopping due to no improvement in F1 score.\")\n",
    "        break  # ÌïôÏäµ Ï§ëÎã®\n",
    "\n",
    "    # Î°úÍ∑∏ Ï∂úÎ†•\n",
    "    log = f\"Epoch {epoch + 1}\\nTrain Loss: {train_loss:.4f}\\nTrain F1 Score: {train_f1:.4f}\\n\"\n",
    "    print(log)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5\n",
      "Fold 1, Epoch 1, Validation F1 Score: 0.8339\n",
      "Fold 1, Epoch 2, Validation F1 Score: 0.8997\n",
      "Fold 1, Epoch 3, Validation F1 Score: 0.9254\n",
      "Fold 1, Epoch 4, Validation F1 Score: 0.9372\n",
      "Fold 1, Epoch 5, Validation F1 Score: 0.9396\n",
      "Fold 1, Epoch 6, Validation F1 Score: 0.9488\n",
      "Fold 1, Epoch 7, Validation F1 Score: 0.9490\n",
      "Fold 1, Epoch 8, Validation F1 Score: 0.9513\n",
      "Fold 1, Epoch 9, Validation F1 Score: 0.9544\n",
      "Fold 1, Epoch 10, Validation F1 Score: 0.9567\n",
      "Fold 1, Epoch 11, Validation F1 Score: 0.9668\n",
      "Fold 1, Epoch 12, Validation F1 Score: 0.9666\n",
      "Fold 1, Epoch 13, Validation F1 Score: 0.9624\n",
      "Fold 1, Epoch 14, Validation F1 Score: 0.9799\n",
      "Fold 1, Epoch 15, Validation F1 Score: 0.9778\n",
      "Fold 1, Epoch 16, Validation F1 Score: 0.9882\n",
      "Fold 1, Epoch 17, Validation F1 Score: 0.9838\n",
      "Fold 1, Epoch 18, Validation F1 Score: 0.9816\n",
      "Epoch 00019: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Fold 1, Epoch 19, Validation F1 Score: 0.9817\n",
      "Early stopping in fold 1 due to no improvement in F1 score.\n",
      "Training fold 2/5\n",
      "Fold 2, Epoch 1, Validation F1 Score: 0.8192\n",
      "Fold 2, Epoch 2, Validation F1 Score: 0.9029\n",
      "Fold 2, Epoch 3, Validation F1 Score: 0.9036\n",
      "Fold 2, Epoch 4, Validation F1 Score: 0.9228\n",
      "Fold 2, Epoch 5, Validation F1 Score: 0.9363\n",
      "Fold 2, Epoch 6, Validation F1 Score: 0.9558\n",
      "Fold 2, Epoch 7, Validation F1 Score: 0.9560\n",
      "Fold 2, Epoch 8, Validation F1 Score: 0.9569\n",
      "Fold 2, Epoch 9, Validation F1 Score: 0.9689\n",
      "Fold 2, Epoch 10, Validation F1 Score: 0.9618\n",
      "Fold 2, Epoch 11, Validation F1 Score: 0.9770\n",
      "Fold 2, Epoch 12, Validation F1 Score: 0.9765\n",
      "Fold 2, Epoch 13, Validation F1 Score: 0.9807\n",
      "Fold 2, Epoch 14, Validation F1 Score: 0.9787\n",
      "Fold 2, Epoch 15, Validation F1 Score: 0.9778\n",
      "Fold 2, Epoch 16, Validation F1 Score: 0.9801\n",
      "Early stopping in fold 2 due to no improvement in F1 score.\n",
      "Training fold 3/5\n",
      "Fold 3, Epoch 1, Validation F1 Score: 0.8115\n",
      "Fold 3, Epoch 2, Validation F1 Score: 0.8793\n",
      "Fold 3, Epoch 3, Validation F1 Score: 0.8949\n",
      "Fold 3, Epoch 4, Validation F1 Score: 0.9271\n",
      "Fold 3, Epoch 5, Validation F1 Score: 0.9411\n",
      "Fold 3, Epoch 6, Validation F1 Score: 0.9494\n",
      "Fold 3, Epoch 7, Validation F1 Score: 0.9484\n",
      "Fold 3, Epoch 8, Validation F1 Score: 0.9552\n",
      "Fold 3, Epoch 9, Validation F1 Score: 0.9626\n",
      "Fold 3, Epoch 10, Validation F1 Score: 0.9654\n",
      "Fold 3, Epoch 11, Validation F1 Score: 0.9698\n",
      "Fold 3, Epoch 12, Validation F1 Score: 0.9685\n",
      "Fold 3, Epoch 13, Validation F1 Score: 0.9716\n",
      "Fold 3, Epoch 14, Validation F1 Score: 0.9769\n",
      "Fold 3, Epoch 15, Validation F1 Score: 0.9799\n",
      "Fold 3, Epoch 16, Validation F1 Score: 0.9735\n",
      "Fold 3, Epoch 17, Validation F1 Score: 0.9730\n",
      "Fold 3, Epoch 18, Validation F1 Score: 0.9809\n",
      "Fold 3, Epoch 19, Validation F1 Score: 0.9801\n",
      "Fold 3, Epoch 20, Validation F1 Score: 0.9815\n",
      "Fold 3, Epoch 21, Validation F1 Score: 0.9809\n",
      "Fold 3, Epoch 22, Validation F1 Score: 0.9866\n",
      "Fold 3, Epoch 23, Validation F1 Score: 0.9831\n",
      "Fold 3, Epoch 24, Validation F1 Score: 0.9859\n",
      "Fold 3, Epoch 25, Validation F1 Score: 0.9766\n",
      "Early stopping in fold 3 due to no improvement in F1 score.\n",
      "Training fold 4/5\n",
      "Fold 4, Epoch 1, Validation F1 Score: 0.8198\n",
      "Fold 4, Epoch 2, Validation F1 Score: 0.8707\n",
      "Fold 4, Epoch 3, Validation F1 Score: 0.8973\n",
      "Fold 4, Epoch 4, Validation F1 Score: 0.9236\n",
      "Fold 4, Epoch 5, Validation F1 Score: 0.9375\n",
      "Fold 4, Epoch 6, Validation F1 Score: 0.9421\n",
      "Fold 4, Epoch 7, Validation F1 Score: 0.9497\n",
      "Fold 4, Epoch 8, Validation F1 Score: 0.9437\n",
      "Fold 4, Epoch 9, Validation F1 Score: 0.9626\n",
      "Fold 4, Epoch 10, Validation F1 Score: 0.9720\n",
      "Fold 4, Epoch 11, Validation F1 Score: 0.9636\n",
      "Fold 4, Epoch 12, Validation F1 Score: 0.9720\n",
      "Fold 4, Epoch 13, Validation F1 Score: 0.9697\n",
      "Fold 4, Epoch 14, Validation F1 Score: 0.9749\n",
      "Fold 4, Epoch 15, Validation F1 Score: 0.9756\n",
      "Fold 4, Epoch 16, Validation F1 Score: 0.9792\n",
      "Fold 4, Epoch 17, Validation F1 Score: 0.9823\n",
      "Fold 4, Epoch 18, Validation F1 Score: 0.9763\n",
      "Fold 4, Epoch 19, Validation F1 Score: 0.9810\n",
      "Fold 4, Epoch 20, Validation F1 Score: 0.9787\n",
      "Early stopping in fold 4 due to no improvement in F1 score.\n",
      "Training fold 5/5\n",
      "Fold 5, Epoch 1, Validation F1 Score: 0.8113\n",
      "Fold 5, Epoch 2, Validation F1 Score: 0.8902\n",
      "Fold 5, Epoch 3, Validation F1 Score: 0.9169\n",
      "Fold 5, Epoch 4, Validation F1 Score: 0.9297\n",
      "Fold 5, Epoch 5, Validation F1 Score: 0.9417\n",
      "Fold 5, Epoch 6, Validation F1 Score: 0.9511\n",
      "Fold 5, Epoch 7, Validation F1 Score: 0.9620\n",
      "Fold 5, Epoch 8, Validation F1 Score: 0.9581\n",
      "Fold 5, Epoch 9, Validation F1 Score: 0.9673\n",
      "Fold 5, Epoch 10, Validation F1 Score: 0.9778\n",
      "Fold 5, Epoch 11, Validation F1 Score: 0.9763\n",
      "Fold 5, Epoch 12, Validation F1 Score: 0.9715\n",
      "Fold 5, Epoch 13, Validation F1 Score: 0.9772\n",
      "Early stopping in fold 5 due to no improvement in F1 score.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Prediction Ï†ÄÏû•ÏÜå Ï¥àÍ∏∞Ìôî\n",
    "fold_predictions = []\n",
    "\n",
    "# K-Fold ÏÑ§Ï†ï\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(trn_dataset.df, trn_dataset.df['target'])):\n",
    "    print(f\"Training fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    # Train/Validation Subset ÏÉùÏÑ±\n",
    "    train_subset = Subset(trn_dataset, train_idx)\n",
    "    val_subset = Subset(trn_dataset, val_idx)\n",
    "    \n",
    "    # DataLoader Ï†ïÏùò\n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=False, drop_last=False)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=False)\n",
    "\n",
    "    # Î™®Îç∏ Ï¥àÍ∏∞Ìôî\n",
    "    model = MultimodalModel(\n",
    "        model_name=model_name,\n",
    "        text_dim=50,  # ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞Ïùò Ï∞®Ïõê\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "    \n",
    "    # ÌïôÏäµ Î£®ÌîÑ\n",
    "    patience = 3\n",
    "    early_stopping_counter = 0\n",
    "    fold_best_f1 = 0\n",
    "    text_weight = 1.5  # ÌäπÏ†ï ÌÅ¥ÎûòÏä§ÏóêÏÑú ÌÖçÏä§Ìä∏ ÎπÑÏ§ëÏùÑ ÎÜíÏù¥Îäî Í∞í\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        preds_list = []\n",
    "        targets_list = []\n",
    "        \n",
    "        for images, text_vectors, targets in train_loader:\n",
    "            images, text_vectors, targets = images.to(device), text_vectors.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # ÌäπÏ†ï ÌÅ¥ÎûòÏä§Ïùò Í≤ΩÏö∞ ÌÖçÏä§Ìä∏ ÎπÑÏ§ëÏùÑ ÎÜíÏûÑ\n",
    "            mask = torch.isin(targets, torch.tensor([3, 4, 7, 14], device=device))\n",
    "            text_vectors = torch.where(mask.unsqueeze(1), text_vectors * text_weight, text_vectors)\n",
    "\n",
    "            # Î™®Îç∏Ïóê Ïù¥ÎØ∏ÏßÄÏôÄ ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞Î•º Ï†ÑÎã¨\n",
    "            outputs = model(images, text_vectors)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "        \n",
    "        # ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ Ï†ÅÏö©\n",
    "        scheduler.step(train_f1)\n",
    "        \n",
    "        # Validation Step\n",
    "        model.eval()\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, text_vectors, targets in val_loader:\n",
    "                images, text_vectors, targets = images.to(device), text_vectors.to(device), targets.to(device)\n",
    "                preds = model(images, text_vectors)\n",
    "                val_preds.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "                val_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        val_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1}, Validation F1 Score: {val_f1:.4f}\")\n",
    "        \n",
    "        # Best F1 Score ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Ï°∞Í∏∞ Ï¢ÖÎ£å Ï≤¥ÌÅ¨\n",
    "        if val_f1 > fold_best_f1:\n",
    "            fold_best_f1 = val_f1\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "        \n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f\"Early stopping in fold {fold + 1} due to no improvement in F1 score.\")\n",
    "            break\n",
    "\n",
    "    # Ìè¥ÎìúÎ≥Ñ ÏòàÏ∏° Ï†ÄÏû•\n",
    "    fold_predictions.append((val_targets, val_preds))\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌïú Ï∂îÎ°†ÏùÑ ÏßÑÌñâÌïòÍ≥†, Í≤∞Í≥º ÌååÏùºÏùÑ Ï†ÄÏû•Ìï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [00:23<00:00,  4.22it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "model.eval()\n",
    "for image, _, _ in tqdm(tst_loader):   # tst_loaderÏóêÏÑúÎäî imageÏôÄ targetÎßå Î∞òÌôò\n",
    "    image = image.to(device)\n",
    "\n",
    "    # ÎçîÎØ∏ ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞ ÏÉùÏÑ± (Ïòà: ÌÅ¨Í∏∞ 50Ïùò Ï†úÎ°ú ÌÖêÏÑú)\n",
    "    text = torch.zeros((image.size(0), 50)).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image, text)  # ÎçîÎØ∏ ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞ÎèÑ Ìï®Íªò Ï†ÑÎã¨\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 [00:23<00:00,  4.25it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "preds_list = []\n",
    "\n",
    "model2.eval()\n",
    "for image, _, _ in tqdm(tst_loader):   # tst_loaderÏóêÏÑúÎäî imageÏôÄ targetÎßå Î∞òÌôò\n",
    "    image = image.to(device)\n",
    "\n",
    "    # ÎçîÎØ∏ ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞ ÏÉùÏÑ± (Ïòà: ÌÅ¨Í∏∞ 50Ïùò Ï†úÎ°ú ÌÖêÏÑú)\n",
    "    text = torch.zeros((image.size(0), 50)).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model2(image, text)  # ÎçîÎØ∏ ÌÖçÏä§Ìä∏ Î≤°ÌÑ∞ÎèÑ Ìï®Íªò Ï†ÑÎã¨\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1700315216829,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "aClN7Qi7VZoh"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315238836,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "VDBXQqAzVvLY"
   },
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"/root/data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1700315244710,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "ePx2vCELVnuS"
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"/root/data/output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3771: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8464: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.4878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0558: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.5407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8217: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5758: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3068: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.7785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0804: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.7505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9699: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0525: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:13<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.8155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0145: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.8386\n",
      "Class 0: F1 Score = 0.9565\n",
      "Class 1: F1 Score = 0.9091\n",
      "Class 2: F1 Score = 0.9697\n",
      "Class 3: F1 Score = 0.3333\n",
      "Class 4: F1 Score = 0.7000\n",
      "Class 5: F1 Score = 0.9474\n",
      "Class 6: F1 Score = 0.9545\n",
      "Class 7: F1 Score = 0.4255\n",
      "Class 8: F1 Score = 1.0000\n",
      "Class 9: F1 Score = 0.9744\n",
      "Class 10: F1 Score = 0.9189\n",
      "Class 11: F1 Score = 0.8800\n",
      "Class 12: F1 Score = 0.9167\n",
      "Class 13: F1 Score = 0.8936\n",
      "Class 14: F1 Score = 0.4762\n",
      "Class 15: F1 Score = 1.0000\n",
      "Class 16: F1 Score = 1.0000\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.5005: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.3571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8983: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0775: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.5824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8866: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.6404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5532: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1546: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.7246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3088: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:13<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.7604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6479: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.7987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7792: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2005: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.8258\n",
      "Class 0: F1 Score = 0.9474\n",
      "Class 1: F1 Score = 0.8780\n",
      "Class 2: F1 Score = 1.0000\n",
      "Class 3: F1 Score = 0.5500\n",
      "Class 4: F1 Score = 0.7500\n",
      "Class 5: F1 Score = 1.0000\n",
      "Class 6: F1 Score = 0.8276\n",
      "Class 7: F1 Score = 0.2857\n",
      "Class 8: F1 Score = 1.0000\n",
      "Class 9: F1 Score = 1.0000\n",
      "Class 10: F1 Score = 0.7568\n",
      "Class 11: F1 Score = 0.7692\n",
      "Class 12: F1 Score = 0.8667\n",
      "Class 13: F1 Score = 0.8511\n",
      "Class 14: F1 Score = 0.5926\n",
      "Class 15: F1 Score = 0.9630\n",
      "Class 16: F1 Score = 1.0000\n",
      "\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4066: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9028: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:13<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.4378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9840: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:13<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.5255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6111: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3577: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.6965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5623: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.7278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8190: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:13<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.7367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2689: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.7899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1302: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.8169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.8462\n",
      "Class 0: F1 Score = 1.0000\n",
      "Class 1: F1 Score = 0.8333\n",
      "Class 2: F1 Score = 1.0000\n",
      "Class 3: F1 Score = 0.4000\n",
      "Class 4: F1 Score = 0.5957\n",
      "Class 5: F1 Score = 1.0000\n",
      "Class 6: F1 Score = 0.9744\n",
      "Class 7: F1 Score = 0.5000\n",
      "Class 8: F1 Score = 1.0000\n",
      "Class 9: F1 Score = 1.0000\n",
      "Class 10: F1 Score = 0.9412\n",
      "Class 11: F1 Score = 0.9412\n",
      "Class 12: F1 Score = 0.8000\n",
      "Class 13: F1 Score = 0.9444\n",
      "Class 14: F1 Score = 0.5000\n",
      "Class 15: F1 Score = 0.9545\n",
      "Class 16: F1 Score = 1.0000\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3049: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.3294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2671: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.4805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7305: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:13<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6904: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8003: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.6318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8578: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.7366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0042: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2207: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.7848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0536: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.7909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9198: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.8156\n",
      "Class 0: F1 Score = 0.9524\n",
      "Class 1: F1 Score = 0.9000\n",
      "Class 2: F1 Score = 1.0000\n",
      "Class 3: F1 Score = 0.5455\n",
      "Class 4: F1 Score = 0.5306\n",
      "Class 5: F1 Score = 0.9583\n",
      "Class 6: F1 Score = 1.0000\n",
      "Class 7: F1 Score = 0.4211\n",
      "Class 8: F1 Score = 0.9091\n",
      "Class 9: F1 Score = 0.9268\n",
      "Class 10: F1 Score = 0.8571\n",
      "Class 11: F1 Score = 0.8649\n",
      "Class 12: F1 Score = 0.8837\n",
      "Class 13: F1 Score = 0.9333\n",
      "Class 14: F1 Score = 0.2400\n",
      "Class 15: F1 Score = 0.9655\n",
      "Class 16: F1 Score = 0.9767\n",
      "\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.6057: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2695: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.4876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7978: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4890: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.6588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5093: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.7303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7311: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.7246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0621: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5857: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9272: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.8131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3711: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:12<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.8204\n",
      "Class 0: F1 Score = 1.0000\n",
      "Class 1: F1 Score = 0.9302\n",
      "Class 2: F1 Score = 1.0000\n",
      "Class 3: F1 Score = 0.4103\n",
      "Class 4: F1 Score = 0.5366\n",
      "Class 5: F1 Score = 1.0000\n",
      "Class 6: F1 Score = 1.0000\n",
      "Class 7: F1 Score = 0.4444\n",
      "Class 8: F1 Score = 0.9412\n",
      "Class 9: F1 Score = 0.9615\n",
      "Class 10: F1 Score = 0.8205\n",
      "Class 11: F1 Score = 0.9796\n",
      "Class 12: F1 Score = 0.6897\n",
      "Class 13: F1 Score = 0.8511\n",
      "Class 14: F1 Score = 0.4118\n",
      "Class 15: F1 Score = 0.9697\n",
      "Class 16: F1 Score = 1.0000\n",
      "\n",
      "Class-wise Average F1 Scores:\n",
      "Class 0: Average F1 Score = 0.9713\n",
      "Class 1: Average F1 Score = 0.8901\n",
      "Class 2: Average F1 Score = 0.9939\n",
      "Class 3: Average F1 Score = 0.4478\n",
      "Class 4: Average F1 Score = 0.6226\n",
      "Class 5: Average F1 Score = 0.9811\n",
      "Class 6: Average F1 Score = 0.9513\n",
      "Class 7: Average F1 Score = 0.4153\n",
      "Class 8: Average F1 Score = 0.9701\n",
      "Class 9: Average F1 Score = 0.9725\n",
      "Class 10: Average F1 Score = 0.8589\n",
      "Class 11: Average F1 Score = 0.8870\n",
      "Class 12: Average F1 Score = 0.8313\n",
      "Class 13: Average F1 Score = 0.8947\n",
      "Class 14: Average F1 Score = 0.4441\n",
      "Class 15: Average F1 Score = 0.9705\n",
      "Class 16: Average F1 Score = 0.9953\n"
     ]
    }
   ],
   "source": [
    "#Ï∂îÍ∞Ä Í≤ÄÏ¶ù : classÎßàÎã§ f1 score Íµ¨Ìï¥ÏÑú ÎÇÆÏùÄ f1 ÎÅåÏñ¥Ïò¨Î†§Î≥¥Í∏∞ \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Í∏∞\n",
    "data_path = '/root/data/train.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "n_splits = 5  # K-Fold split Ïàò ÏÑ§Ï†ï\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# K-Fold ÏÑ§Ï†ï\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§Î≥Ñ F1 Ïä§ÏΩîÏñ¥Î•º Ï†ÄÏû•Ìï† ÎîïÏÖîÎÑàÎ¶¨\n",
    "class_f1_scores = defaultdict(list)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['target'])):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Train/Validation Îç∞Ïù¥ÌÑ∞ Î∂ÑÎ¶¨\n",
    "    train_subset = Subset(trn_dataset, train_idx)\n",
    "    val_subset = Subset(trn_dataset, val_idx)\n",
    "    \n",
    "    # DataLoader Ï†ïÏùò\n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Î™®Îç∏ Ï¥àÍ∏∞Ìôî\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # ÌïôÏäµ Î£®ÌîÑ\n",
    "    best_f1 = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_one_epoch(train_loader, model, optimizer, loss_fn, device=device)\n",
    "        \n",
    "        # Í≤ÄÏ¶ù Î£®ÌîÑ\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "                preds = model(images)\n",
    "                val_preds.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "                val_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        # Fold F1 Ïä§ÏΩîÏñ¥ Í≥ÑÏÇ∞\n",
    "        fold_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "        print(f\"Fold {fold + 1} F1 Score: {fold_f1:.4f}\")\n",
    "        \n",
    "        if fold_f1 > best_f1:\n",
    "            best_f1 = fold_f1\n",
    "\n",
    "    # ÌÅ¥ÎûòÏä§Î≥Ñ F1 Ïä§ÏΩîÏñ¥ Í≥ÑÏÇ∞\n",
    "    class_report = classification_report(val_targets, val_preds, output_dict=True)\n",
    "    for class_id in range(17):\n",
    "        f1_score_class = class_report[str(class_id)]['f1-score']\n",
    "        class_f1_scores[class_id].append(f1_score_class)\n",
    "        print(f\"Class {class_id}: F1 Score = {f1_score_class:.4f}\")\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§Î≥Ñ ÌèâÍ∑† F1 Ïä§ÏΩîÏñ¥ Ï∂úÎ†•\n",
    "print(\"\\nClass-wise Average F1 Scores:\")\n",
    "for class_id, scores in class_f1_scores.items():\n",
    "    avg_f1_score = np.mean(scores)\n",
    "    print(f\"Class {class_id}: Average F1 Score = {avg_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class 3,7,14 f1 score ÎÑàÎ¨¥ ÎÇÆÏùå + 4 ÎèÑ Ï∂îÍ∞ÄÎ°ú Î≥¥Î©¥ Ï¢ãÏùÑÍ≤É\n",
    "3,confirmation_of_admission_and_discharge\n",
    "7,medical_outpatient_certificate\n",
    "14,statement_of_opinion\n",
    "\n",
    "4,diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Î©îÎ™®Î¶¨ Ï¥àÍ∏∞Ìôî\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
