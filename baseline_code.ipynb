{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "# **📄 Document type classification baseline code**\n",
    "## Contents\n",
    "- Prepare Environments\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n",
    "* 필요한 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21945,
     "status": "ok",
     "timestamp": 1700314517484,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "pUjnEto4gIZm",
    "outputId": "0999f10c-e1ff-428c-995b-481eec8a0b58"
   },
   "outputs": [],
   "source": [
    "# 구글 드라이브 마운트, Colab을 이용하지 않는다면 패스해도 됩니다.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7640,
     "status": "ok",
     "timestamp": 1700314537985,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "5lFQ-gpjnN_m"
   },
   "outputs": [],
   "source": [
    "# 구글 드라이브에 업로드된 대회 데이터를 압축 해제하고 로컬에 저장합니다.\n",
    "!tar -xvf drive/MyDrive/datasets_fin.tar > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 설치합니다.\n",
    "!pip install timm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import augraphy as ag\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import re \n",
    "from PIL import ImageEnhance, ImageFilter\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from collections import Counter\n",
    "import pytesseract\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "#oversampling -> 클래스 빈 130개 채워서 1700개 : max_oversample 로 배율 조정\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None, oversample=False, max_oversample=4, use_ocr=False):\n",
    "        self.df = pd.read_csv(csv)\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.oversample = oversample\n",
    "        self.max_oversample = max_oversample\n",
    "        self.use_ocr = use_ocr\n",
    "\n",
    "        # OCR 대상 클래스 텍스트 추출 및 벡터화\n",
    "        if self.use_ocr:\n",
    "            ocr_texts = [\n",
    "                extract_text_from_image(os.path.join(self.path, row['ID'])) \n",
    "                if row['target'] in [3, 4, 7, 14] else \"\" \n",
    "                for _, row in self.df.iterrows()\n",
    "            ]\n",
    "            self.text_vectors = text_to_vector(ocr_texts)\n",
    "        else:\n",
    "            self.text_vectors = [np.zeros(50) for _ in range(len(self.df))]  # OCR 비활성화 시 기본 0 벡터 사용\n",
    "            \n",
    "        if self.oversample:\n",
    "            self.df, self.text_vectors = self.apply_oversampling(self.df, self.text_vectors)\n",
    "\n",
    "    def apply_oversampling(self, df, text_vectors):\n",
    "        class_counts = Counter(df['target'])\n",
    "        max_count = int(max(class_counts.values()) * self.max_oversample)  # 설정한 배수만큼 샘플 수 제한\n",
    "        oversampled_df = df.copy()\n",
    "        oversampled_text_vectors = text_vectors[:]\n",
    "\n",
    "        for cls, count in class_counts.items():\n",
    "            if count < max_count:\n",
    "                # 부족한 샘플 수만큼 추가 복제\n",
    "                samples_to_add = df[df['target'] == cls]\n",
    "                text_vectors_to_add = [text_vectors[i] for i in samples_to_add.index]\n",
    "                \n",
    "                for _ in range(max_count // count - 1):  # 배수만큼 추가\n",
    "                    oversampled_df = pd.concat([oversampled_df, samples_to_add])\n",
    "                    oversampled_text_vectors.extend(text_vectors_to_add)\n",
    "                \n",
    "                # 나머지 추가 복제\n",
    "                remainder = max_count % count\n",
    "                if remainder > 0:\n",
    "                    oversampled_df = pd.concat([oversampled_df, samples_to_add.sample(remainder, replace=True)])\n",
    "                    oversampled_text_vectors.extend(text_vectors_to_add[:remainder])\n",
    "\n",
    "        return oversampled_df.sample(frac=1).reset_index(drop=True), oversampled_text_vectors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_name = self.df.iloc[idx]['ID']\n",
    "        target = self.df.iloc[idx]['target']\n",
    "        img_path = os.path.join(self.path, image_name)\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        \n",
    "        # OCR 텍스트 벡터 가져오기\n",
    "        text_vector = self.text_vectors[idx] if self.use_ocr and target in [3, 4, 7, 14] else np.zeros(50)\n",
    "        \n",
    "        return img, torch.tensor(text_vector, dtype=torch.float32), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_for_ocr(img):\n",
    "    # 이미지 확대\n",
    "    img = img.resize((img.width * 2, img.height * 2), Image.LANCZOS)\n",
    "    \n",
    "    # 밝기 및 대비 조절\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(2)  # 대비 증가\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(1.5)  # 밝기 증가\n",
    "    \n",
    "    # 이미지 날카로움 증가\n",
    "    img = img.filter(ImageFilter.SHARPEN)\n",
    "    \n",
    "    # Augraphy 변형 설정 및 적용\n",
    "    pipeline = ag.Compose([\n",
    "        ag.DirtyRollers(p=0.5),    # 먼지 효과 추가\n",
    "        ag.NoiseTexturize(p=0.5),  # 노이즈 텍스처화\n",
    "        ag.Brighten(p=0.3, factor=(1.25, 1.5)),  # 밝기 증가\n",
    "        ag.FoldingEffect(p=0.5, fold_height=(5, 20), fold_width=(5, 15), gradient_width=(0.1, 0.3)),\n",
    "        ag.InkBleed(p=0.3, intensity_range=(0.1, 0.2)),\n",
    "        ag.InkMottling(p=0.3, severity=(0.2, 0.4)),\n",
    "        ag.SubtleNoiseTexturize(p=0.4, sigma=(0.1, 0.3)),\n",
    "        ag.GaussianBlur(p=0.3, sigma=(0.1, 1.5)),\n",
    "        ag.LowInkLine(p=0.4, count_range=(2, 5), use_consistent_lines=False),\n",
    "        ag.Jitter(p=0.3, sigma=(1, 2)),\n",
    "        ag.LightingGradient(p=0.5, transparency=(0.75, 0.85), direction=0.5),\n",
    "        ag.Watermark(p=0.3, text=\"CONFIDENTIAL\", font_size_range=(20, 40), rotation_range=(0, 90))\n",
    "    ])\n",
    "    \n",
    "    # Augraphy로 변형 적용\n",
    "    img = pipeline(img)\n",
    "\n",
    "    # 노이즈 제거 및 이진화 처리\n",
    "    img = img.convert('L')  # 그레이스케일로 변환\n",
    "    threshold = 140  # 이진화 임계값 설정\n",
    "    img = img.point(lambda p: p > threshold and 255)  # 이진화 적용\n",
    "\n",
    "    return img\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    # 이미지 열기 및 전처리\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = preprocess_image_for_ocr(img)  \n",
    "    # OCR로 텍스트 추출 (한국어+영어)\n",
    "    text = pytesseract.image_to_string(img, lang='kor', config='--psm 6')\n",
    "    # 특수 문자 제거 (필요에 따라 조정)\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)  \n",
    "    return text.strip()\n",
    "\n",
    "# 텍스트 벡터화 (TF-IDF + 차원 축소)\n",
    "def text_to_vector(texts):\n",
    "    vectorizer = TfidfVectorizer(max_features=500)\n",
    "    text_vectors = vectorizer.fit_transform(texts)\n",
    "    svd = TruncatedSVD(n_components=50)  # 차원 축소\n",
    "    text_vectors = svd.fit_transform(text_vectors)\n",
    "    return text_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, gamma=2.0, weight=None):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha  # Focal Loss \n",
    "        self.gamma = gamma  # Focal Loss의 \n",
    "        self.weight = weight  # Cross-Entropy \n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # Cross-Entropy \n",
    "        cross_entropy_loss = F.cross_entropy(outputs, targets, weight=self.weight)\n",
    "\n",
    "        # Focal Loss \n",
    "        ce_loss = F.cross_entropy(outputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)  # 예측 확률\n",
    "        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "        total_loss = self.alpha * focal_loss + (1 - self.alpha) * cross_entropy_loss\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "#Mixed Precision Training\n",
    "\n",
    "scaler = GradScaler()  # Mixed Precision Training을 위한 스케일러 초기화\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, text, targets in pbar:\n",
    "        image, text, targets = image.to(device), text.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast():  # Mixed Precision 적용\n",
    "            preds = model(image, text)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 샘플 수:\n",
      " target\n",
      "16    100\n",
      "10    100\n",
      "0     100\n",
      "3     100\n",
      "12    100\n",
      "8     100\n",
      "2     100\n",
      "11    100\n",
      "7     100\n",
      "9     100\n",
      "15    100\n",
      "5     100\n",
      "4     100\n",
      "6     100\n",
      "13     74\n",
      "14     50\n",
      "1      46\n",
      "Name: count, dtype: int64\n",
      "클래스별 비율:\n",
      " target\n",
      "16    0.063694\n",
      "10    0.063694\n",
      "0     0.063694\n",
      "3     0.063694\n",
      "12    0.063694\n",
      "8     0.063694\n",
      "2     0.063694\n",
      "11    0.063694\n",
      "7     0.063694\n",
      "9     0.063694\n",
      "15    0.063694\n",
      "5     0.063694\n",
      "4     0.063694\n",
      "6     0.063694\n",
      "13    0.047134\n",
      "14    0.031847\n",
      "1     0.029299\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data_sample = pd.read_csv(\"/root/data/train.csv\")  # 훈련 데이터 파일\n",
    "\n",
    "# 클래스 분포 확인\n",
    "class_counts = data_sample['target'].value_counts()\n",
    "print(\"클래스별 샘플 수:\\n\", class_counts)\n",
    "\n",
    "# 비율 계산\n",
    "total_count = len(data_sample)\n",
    "class_ratios = class_counts / total_count\n",
    "print(\"클래스별 비율:\\n\", class_ratios)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Class Distribution in Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '/root/data'\n",
    "\n",
    "# model config\n",
    "model_name = 'tf_efficientnetv2_m' # 'resnet50' 'efficientnet-b0', ...\n",
    "model_name2 = 'convnext_small'\n",
    "\n",
    "# training config\n",
    "img_size = 288\n",
    "LR = 1e-4\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 클래스별 이미지 통계 계산 함수\n",
    "def calculate_class_stats(df, img_dir):\n",
    "    class_stats = defaultdict(list)\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_path = f\"{img_dir}/{row['ID']}\"  # 이미지 경로\n",
    "        target = row['target']  # 클래스 레이블\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # tensor \n",
    "        img_array = np.array(transforms.ToTensor()(img).permute(1, 2, 0))\n",
    "        \n",
    "        # 각 채널별 평균과 표준편차 계산\n",
    "        mean = img_array.mean(axis=(0, 1))\n",
    "        std = img_array.std(axis=(0, 1))\n",
    "        \n",
    "        # 클래스별로 평균과 표준편차 저장\n",
    "        class_stats[target].append((mean, std))\n",
    "    \n",
    "    # 각 클래스별 평균과 표준편차의 평균 계산\n",
    "    class_mean_std = {\n",
    "        cls: (np.mean([s[0] for s in stats], axis=0), np.mean([s[1] for s in stats], axis=0))\n",
    "        for cls, stats in class_stats.items()\n",
    "    }\n",
    "    return class_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1570/1570 [00:28<00:00, 55.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 16 - Mean: [0.4219013  0.4295417  0.42146945], Std: [0.2373147  0.23417273 0.23942035]\n",
      "클래스 10 - Mean: [0.6575105  0.66326165 0.6644608 ], Std: [0.13163847 0.12877204 0.12457712]\n",
      "클래스 4 - Mean: [0.6555603  0.66125077 0.66331756], Std: [0.15522847 0.15262605 0.14899264]\n",
      "클래스 5 - Mean: [0.4437757  0.45977414 0.46266812], Std: [0.3156187  0.3196577  0.31643304]\n",
      "클래스 15 - Mean: [0.6350243  0.64473253 0.6507628 ], Std: [0.1678749  0.16353387 0.15797006]\n",
      "클래스 14 - Mean: [0.6480721  0.6549895  0.65739745], Std: [0.13476998 0.13317542 0.13080387]\n",
      "클래스 9 - Mean: [0.5308454  0.5393029  0.54112315], Std: [0.3078833  0.30661288 0.3008869 ]\n",
      "클래스 13 - Mean: [0.6464133 0.6576297 0.6628065], Std: [0.16119514 0.1606536  0.1597504 ]\n",
      "클래스 7 - Mean: [0.63879293 0.6516734  0.6549295 ], Std: [0.14560634 0.14385152 0.14064762]\n",
      "클래스 11 - Mean: [0.5965798  0.61167085 0.6179784 ], Std: [0.18097693 0.17057073 0.17047977]\n",
      "클래스 2 - Mean: [0.29230753 0.26621136 0.2712087 ], Std: [0.19488445 0.18460369 0.18703903]\n",
      "클래스 8 - Mean: [0.4591894  0.48785004 0.5136458 ], Std: [0.2949226  0.30572063 0.31396866]\n",
      "클래스 12 - Mean: [0.6531739  0.6636219  0.66996545], Std: [0.13231365 0.12964574 0.1266244 ]\n",
      "클래스 3 - Mean: [0.65375656 0.6593415  0.6593775 ], Std: [0.14589216 0.14422888 0.14131746]\n",
      "클래스 0 - Mean: [0.5997213  0.61057276 0.6175231 ], Std: [0.151559   0.149929   0.14750864]\n",
      "클래스 1 - Mean: [0.6672302 0.6775926 0.6834501], Std: [0.14367767 0.14226489 0.13918385]\n",
      "클래스 6 - Mean: [0.6696616  0.6832548  0.69261336], Std: [0.1630469  0.150923   0.14306074]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/root/data/train.csv\")  # 훈련 데이터프레임 불러오기\n",
    "img_dir = \"/root/data/train\"  # 이미지 디렉토리 경로\n",
    "class_mean_std = calculate_class_stats(df, img_dir)\n",
    "\n",
    "# 각 클래스의 평균과 표준편차 출력\n",
    "for cls, (mean, std) in class_mean_std.items():\n",
    "    print(f\"클래스 {cls} - Mean: {mean}, Std: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58055977, 0.58954542, 0.59439398]),\n",
       " array([0.18614137, 0.18358485, 0.18168615]))"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스별 평균(mean)과 표준편차(std) 값 저장\n",
    "means = np.array([\n",
    "    [0.4219013, 0.4295417, 0.42146945],\n",
    "    [0.6575105, 0.66326165, 0.6644608],\n",
    "    [0.6555603, 0.66125077, 0.66331756],\n",
    "    [0.4437757, 0.45977414, 0.46266812],\n",
    "    [0.6350243, 0.64473253, 0.6507628],\n",
    "    [0.6480721, 0.6549895, 0.65739745],\n",
    "    [0.5308454, 0.5393029, 0.54112315],\n",
    "    [0.6464133, 0.6576297, 0.6628065],\n",
    "    [0.63879293, 0.6516734, 0.6549295],\n",
    "    [0.5965798, 0.61167085, 0.6179784],\n",
    "    [0.29230753, 0.26621136, 0.2712087],\n",
    "    [0.4591894, 0.48785004, 0.5136458],\n",
    "    [0.6531739, 0.6636219, 0.66996545],\n",
    "    [0.65375656, 0.6593415, 0.6593775],\n",
    "    [0.5997213, 0.61057276, 0.6175231],\n",
    "    [0.6672302, 0.6775926, 0.6834501],\n",
    "    [0.6696616, 0.6832548, 0.69261336]\n",
    "])\n",
    "\n",
    "stds = np.array([\n",
    "    [0.2373147, 0.23417273, 0.23942035],\n",
    "    [0.13163847, 0.12877204, 0.12457712],\n",
    "    [0.15522847, 0.15262605, 0.14899264],\n",
    "    [0.3156187, 0.3196577, 0.31643304],\n",
    "    [0.1678749, 0.16353387, 0.15797006],\n",
    "    [0.13476998, 0.13317542, 0.13080387],\n",
    "    [0.3078833, 0.30661288, 0.3008869],\n",
    "    [0.16119514, 0.1606536, 0.1597504],\n",
    "    [0.14560634, 0.14385152, 0.14064762],\n",
    "    [0.18097693, 0.17057073, 0.17047977],\n",
    "    [0.19488445, 0.18460369, 0.18703903],\n",
    "    [0.2949226, 0.30572063, 0.31396866],\n",
    "    [0.13231365, 0.12964574, 0.1266244],\n",
    "    [0.14589216, 0.14422888, 0.14131746],\n",
    "    [0.151559, 0.149929, 0.14750864],\n",
    "    [0.14367767, 0.14226489, 0.13918385],\n",
    "    [0.1630469, 0.150923, 0.14306074]\n",
    "])\n",
    "\n",
    "# 전체 평균(mean)과 표준편차(std)를 계산\n",
    "overall_mean = means.mean(axis=0)\n",
    "overall_std = stds.mean(axis=0)\n",
    "\n",
    "overall_mean, overall_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터에 대한 Transform 코드\n",
    "\n",
    "trn_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.RandomResizedCrop(height=img_size, width=img_size, scale=(0.8, 1.2), ratio=(0.75, 1.33), p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=(-40,40), p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.RandomGamma(p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=16, max_width=16, min_holes=1, fill_value=0, p=0.5),\n",
    "    A.MotionBlur(blur_limit=5, p=0.2),\n",
    "    A.GaussianBlur(blur_limit=(3,7), p=0.2),\n",
    "    A.GaussNoise(always_apply=False, var_limit=(50.0, 200.0), p=0.5, per_channel=True, mean= 0.0),\n",
    "    A.Affine(shear=15, rotate=10, scale=(0.9, 1.1), p=0.5),\n",
    "    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n",
    "    A.GridDistortion(p=0.3),\n",
    "    A.ImageCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.3), \n",
    "    \n",
    "    # 추가 \n",
    "    A.GridDropout(ratio=0.5, holes_number_x=3, holes_number_y=3, p=0.3),  # GridMask\n",
    "    A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.3),\n",
    "    A.ChannelShuffle(p=0.1),\n",
    "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, p=0.2),\n",
    "    A.Sharpen(alpha=(0.2, 0.5), lightness=(0.5, 1.0), p=0.2),  # 이미지 선명화 추가\n",
    "    A.Normalize(mean=[0.5805, 0.5895, 0.5944], std=[0.186, 0.183, 0.187]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# 테스트 데이터에 대한 Transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.5805, 0.5895, 0.5944], std=[0.186, 0.183, 0.187]),\n",
    "    ToTensorV2(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "INxdmsStop2L",
    "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6800 3140\n"
     ]
    }
   ],
   "source": [
    "# Dataset 정의\n",
    "trn_dataset = ImageDataset(\n",
    "    \"/root/data/train.csv\",\n",
    "    \"/root/data/train/\",\n",
    "    transform=trn_transform,\n",
    "    oversample=True\n",
    ")\n",
    "tst_dataset = ImageDataset(\n",
    "    \"/root/data/sample_submission.csv\",\n",
    "    \"/root/data/test/\",\n",
    "    transform=tst_transform\n",
    ")\n",
    "print(len(trn_dataset), len(tst_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "_sO03fWaQj1h"
   },
   "outputs": [],
   "source": [
    "# DataLoader 정의\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False,\n",
    "    drop_last=False\n",
    ")\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['efficientnet_b0', 'efficientnet_b0_g8_gn', 'efficientnet_b0_g16_evos', 'efficientnet_b0_gn', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b3', 'efficientnet_b3_g8_gn', 'efficientnet_b3_gn', 'efficientnet_b3_pruned', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_b8', 'efficientnet_cc_b0_4e', 'efficientnet_cc_b0_8e', 'efficientnet_cc_b1_8e', 'efficientnet_el', 'efficientnet_el_pruned', 'efficientnet_em', 'efficientnet_es', 'efficientnet_es_pruned', 'efficientnet_l2', 'efficientnet_lite0', 'efficientnet_lite1', 'efficientnet_lite2', 'efficientnet_lite3', 'efficientnet_lite4', 'efficientnetv2_l', 'efficientnetv2_m', 'efficientnetv2_rw_m', 'efficientnetv2_rw_s', 'efficientnetv2_rw_t', 'efficientnetv2_s', 'efficientnetv2_xl', 'gc_efficientnetv2_rw_t', 'tf_efficientnet_b0', 'tf_efficientnet_b1', 'tf_efficientnet_b2', 'tf_efficientnet_b3', 'tf_efficientnet_b4', 'tf_efficientnet_b5', 'tf_efficientnet_b6', 'tf_efficientnet_b7', 'tf_efficientnet_b8', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_efficientnetv2_b0', 'tf_efficientnetv2_b1', 'tf_efficientnetv2_b2', 'tf_efficientnetv2_b3', 'tf_efficientnetv2_l', 'tf_efficientnetv2_m', 'tf_efficientnetv2_s', 'tf_efficientnetv2_xl']\n"
     ]
    }
   ],
   "source": [
    "print(timm.list_models(\"*efficientnet*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, model_name, text_dim=50, num_classes=17, text_weight=1.5):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "        self.image_model = timm.create_model(model_name, pretrained=True, num_classes=0)  # 최종 분류 레이어 제거\n",
    "        self.text_fc = nn.Linear(text_dim, 256)  # 텍스트 벡터를 위한 추가 레이어\n",
    "        self.classifier = nn.Linear(256 + self.image_model.num_features, num_classes)  # 이미지와 텍스트 특징 결합\n",
    "        self.text_weight = text_weight\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        img_features = self.image_model(image)\n",
    "        text_features = self.text_fc(text)\n",
    "        \n",
    "        # 이미지와 텍스트 특징을 결합하여 최종 분류 레이어에 전달\n",
    "        combined_features = torch.cat([img_features, text_features], dim=1)\n",
    "        return self.classifier(combined_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class MultimodalModel2(nn.Module):\n",
    "    def __init__(self, model_name2, text_dim=50, num_classes=17, text_weight=1.5):\n",
    "        super(MultimodalModel2, self).__init__()\n",
    "        self.image_model = timm.create_model(model_name2, pretrained=True, num_classes=0)  # 최종 분류 레이어 제거\n",
    "        self.text_fc = nn.Linear(text_dim, 256)  # 텍스트 벡터를 위한 추가 레이어\n",
    "        self.classifier = nn.Linear(256 + self.image_model.num_features, num_classes)  # 이미지와 텍스트 특징 결합\n",
    "        self.text_weight = text_weight\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        img_features = self.image_model(image)\n",
    "        text_features = self.text_fc(text)\n",
    "        \n",
    "        # 이미지와 텍스트 특징을 결합하여 최종 분류 레이어에 전달\n",
    "        combined_features = torch.cat([img_features, text_features], dim=1)\n",
    "        return self.classifier(combined_features)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1700315114067,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "FbBgFPsLT-CO"
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "#loss_fn = FocalLoss(alpha=1, gamma=2)\n",
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([1.0] * 17).to(device) \n",
    "class_weights[[3, 4, 7, 14]] *= 2 \n",
    "\n",
    "model = MultimodalModel(\n",
    "    model_name=model_name,\n",
    "    text_dim=50,  # 텍스트 벡터의 차원\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "\n",
    "#loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1,weight=class_weights)\n",
    "loss_fn = CombinedLoss(alpha=0.5, gamma=2.0, weight=class_weights).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class_weights = torch.tensor([1.0] * 17).to(device) \n",
    "class_weights[[3, 4, 7, 14]] *= 2 \n",
    "\n",
    "model2 = MultimodalModel(\n",
    "    model_name=model_name2,\n",
    "    text_dim=50,  # 텍스트 벡터의 차원\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "\n",
    "#loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1,weight=class_weights)\n",
    "loss_fn = CombinedLoss(alpha=0.5, gamma=2.0, weight=class_weights).to(device)\n",
    "optimizer = AdamW(model2.parameters(), lr=LR, weight_decay=1e-4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8778,
     "status": "ok",
     "timestamp": 1700315122843,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "OvIVcSRgUPtS",
    "outputId": "88230bf2-976f-45f6-b3b7-1a2d0ad00548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.9963\n",
      "Train F1 Score: 0.6705\n",
      "\n",
      "Epoch 2\n",
      "Train Loss: 0.3231\n",
      "Train F1 Score: 0.8830\n",
      "\n",
      "Epoch 3\n",
      "Train Loss: 0.2142\n",
      "Train F1 Score: 0.9161\n",
      "\n",
      "Epoch 4\n",
      "Train Loss: 0.1669\n",
      "Train F1 Score: 0.9380\n",
      "\n",
      "Epoch 5\n",
      "Train Loss: 0.1407\n",
      "Train F1 Score: 0.9459\n",
      "\n",
      "Epoch 6\n",
      "Train Loss: 0.1242\n",
      "Train F1 Score: 0.9527\n",
      "\n",
      "Epoch 7\n",
      "Train Loss: 0.1002\n",
      "Train F1 Score: 0.9647\n",
      "\n",
      "Epoch 8\n",
      "Train Loss: 0.0956\n",
      "Train F1 Score: 0.9653\n",
      "\n",
      "Epoch 9\n",
      "Train Loss: 0.0836\n",
      "Train F1 Score: 0.9690\n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.0772\n",
      "Train F1 Score: 0.9731\n",
      "\n",
      "Epoch 11\n",
      "Train Loss: 0.0757\n",
      "Train F1 Score: 0.9728\n",
      "\n",
      "Epoch 12\n",
      "Train Loss: 0.0616\n",
      "Train F1 Score: 0.9777\n",
      "\n",
      "Epoch 13\n",
      "Train Loss: 0.0679\n",
      "Train F1 Score: 0.9755\n",
      "\n",
      "Epoch 14\n",
      "Train Loss: 0.0599\n",
      "Train F1 Score: 0.9796\n",
      "\n",
      "Epoch 15\n",
      "Train Loss: 0.0512\n",
      "Train F1 Score: 0.9813\n",
      "\n",
      "Epoch 16\n",
      "Train Loss: 0.0497\n",
      "Train F1 Score: 0.9825\n",
      "\n",
      "Epoch 17\n",
      "Train Loss: 0.0509\n",
      "Train F1 Score: 0.9820\n",
      "\n",
      "Epoch 18\n",
      "Train Loss: 0.0475\n",
      "Train F1 Score: 0.9830\n",
      "\n",
      "Epoch 19\n",
      "Train Loss: 0.0463\n",
      "Train F1 Score: 0.9824\n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.0450\n",
      "Train F1 Score: 0.9850\n",
      "\n",
      "Epoch 21\n",
      "Train Loss: 0.0388\n",
      "Train F1 Score: 0.9850\n",
      "\n",
      "Epoch 22\n",
      "Train Loss: 0.0500\n",
      "Train F1 Score: 0.9837\n",
      "\n",
      "Epoch 23\n",
      "Train Loss: 0.0334\n",
      "Train F1 Score: 0.9884\n",
      "\n",
      "Epoch 24\n",
      "Train Loss: 0.0400\n",
      "Train F1 Score: 0.9851\n",
      "\n",
      "Epoch 25\n",
      "Train Loss: 0.0348\n",
      "Train F1 Score: 0.9882\n",
      "\n",
      "Epoch 00026: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 26\n",
      "Train Loss: 0.0461\n",
      "Train F1 Score: 0.9844\n",
      "\n",
      "Epoch 27\n",
      "Train Loss: 0.0284\n",
      "Train F1 Score: 0.9910\n",
      "\n",
      "Epoch 28\n",
      "Train Loss: 0.0192\n",
      "Train F1 Score: 0.9928\n",
      "\n",
      "Epoch 29\n",
      "Train Loss: 0.0190\n",
      "Train F1 Score: 0.9921\n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.0187\n",
      "Train F1 Score: 0.9934\n",
      "\n",
      "Epoch 31\n",
      "Train Loss: 0.0191\n",
      "Train F1 Score: 0.9926\n",
      "\n",
      "Epoch 32\n",
      "Train Loss: 0.0187\n",
      "Train F1 Score: 0.9935\n",
      "\n",
      "Epoch 33\n",
      "Train Loss: 0.0179\n",
      "Train F1 Score: 0.9947\n",
      "\n",
      "Epoch 34\n",
      "Train Loss: 0.0198\n",
      "Train F1 Score: 0.9929\n",
      "\n",
      "Epoch 35\n",
      "Train Loss: 0.0192\n",
      "Train F1 Score: 0.9929\n",
      "\n",
      "Epoch 00036: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 36\n",
      "Train Loss: 0.0130\n",
      "Train F1 Score: 0.9946\n",
      "\n",
      "Epoch 37\n",
      "Train Loss: 0.0116\n",
      "Train F1 Score: 0.9962\n",
      "\n",
      "Epoch 38\n",
      "Train Loss: 0.0152\n",
      "Train F1 Score: 0.9954\n",
      "\n",
      "Epoch 39\n",
      "Train Loss: 0.0108\n",
      "Train F1 Score: 0.9965\n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.0105\n",
      "Train F1 Score: 0.9971\n",
      "\n",
      "Epoch 41\n",
      "Train Loss: 0.0124\n",
      "Train F1 Score: 0.9957\n",
      "\n",
      "Epoch 42\n",
      "Train Loss: 0.0078\n",
      "Train F1 Score: 0.9971\n",
      "\n",
      "Epoch 00043: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Epoch 43\n",
      "Train Loss: 0.0095\n",
      "Train F1 Score: 0.9969\n",
      "\n",
      "Epoch 44\n",
      "Train Loss: 0.0073\n",
      "Train F1 Score: 0.9971\n",
      "\n",
      "Epoch 45\n",
      "Train Loss: 0.0078\n",
      "Train F1 Score: 0.9972\n",
      "\n",
      "Epoch 46\n",
      "Train Loss: 0.0110\n",
      "Train F1 Score: 0.9966\n",
      "\n",
      "Epoch 47\n",
      "Train Loss: 0.0103\n",
      "Train F1 Score: 0.9966\n",
      "\n",
      "Epoch 48\n",
      "Train Loss: 0.0065\n",
      "Train F1 Score: 0.9984\n",
      "\n",
      "Epoch 49\n",
      "Train Loss: 0.0098\n",
      "Train F1 Score: 0.9972\n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.0063\n",
      "Train F1 Score: 0.9975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "# 조기 종료 설정\n",
    "patience = 5  # 개선되지 않는 에포크 수\n",
    "best_f1 = 0   # 최고 F1 스코어\n",
    "early_stopping_counter = 0  # 조기 종료 카운터\n",
    "\n",
    "# 학습률 스케줄러 설정\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "#scheduler = OneCycleLR(optimizer, max_lr=LR, steps_per_epoch=len(trn_loader), epochs=EPOCHS)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    text_weight = 1.5  # 특정 클래스에서 텍스트 비중을 높이는 값\n",
    "\n",
    "    for images, text_vectors, targets in trn_loader:\n",
    "        images, text_vectors, targets = images.to(device), text_vectors.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 특정 클래스의 경우 텍스트 비중을 높임\n",
    "        mask = torch.isin(targets, torch.tensor([3, 4, 7, 14], device=device))\n",
    "        text_vectors = torch.where(mask.unsqueeze(1), text_vectors * text_weight, text_vectors)\n",
    "\n",
    "        # 모델에 이미지와 텍스트 벡터를 전달\n",
    "        outputs = model(images, text_vectors)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    train_loss /= len(trn_loader)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    # Scheduler step을 F1 스코어 기준으로 조정\n",
    "    scheduler.step(train_f1)\n",
    "\n",
    "    # F1 스코어 개선 확인\n",
    "    if train_f1 > best_f1:\n",
    "        best_f1 = train_f1  # 최고 F1 갱신\n",
    "        early_stopping_counter = 0  # 카운터 초기화\n",
    "    else:\n",
    "        early_stopping_counter += 1  # 개선되지 않으면 카운터 증가\n",
    "\n",
    "    # 조기 종료 조건 확인\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(\"Early stopping due to no improvement in F1 score.\")\n",
    "        break  # 학습 중단\n",
    "\n",
    "    # 로그 출력\n",
    "    log = f\"Epoch {epoch + 1}\\nTrain Loss: {train_loss:.4f}\\nTrain F1 Score: {train_f1:.4f}\\n\"\n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.9385\n",
      "Train F1 Score: 0.6477\n",
      "\n",
      "Epoch 2\n",
      "Train Loss: 0.3658\n",
      "Train F1 Score: 0.8581\n",
      "\n",
      "Epoch 3\n",
      "Train Loss: 0.2726\n",
      "Train F1 Score: 0.8919\n",
      "\n",
      "Epoch 4\n",
      "Train Loss: 0.2088\n",
      "Train F1 Score: 0.9149\n",
      "\n",
      "Epoch 5\n",
      "Train Loss: 0.1830\n",
      "Train F1 Score: 0.9271\n",
      "\n",
      "Epoch 6\n",
      "Train Loss: 0.1642\n",
      "Train F1 Score: 0.9368\n",
      "\n",
      "Epoch 7\n",
      "Train Loss: 0.1547\n",
      "Train F1 Score: 0.9386\n",
      "\n",
      "Epoch 8\n",
      "Train Loss: 0.1537\n",
      "Train F1 Score: 0.9432\n",
      "\n",
      "Epoch 9\n",
      "Train Loss: 0.1369\n",
      "Train F1 Score: 0.9476\n",
      "\n",
      "Epoch 10\n",
      "Train Loss: 0.1174\n",
      "Train F1 Score: 0.9558\n",
      "\n",
      "Epoch 11\n",
      "Train Loss: 0.1184\n",
      "Train F1 Score: 0.9549\n",
      "\n",
      "Epoch 12\n",
      "Train Loss: 0.0969\n",
      "Train F1 Score: 0.9612\n",
      "\n",
      "Epoch 13\n",
      "Train Loss: 0.0973\n",
      "Train F1 Score: 0.9651\n",
      "\n",
      "Epoch 14\n",
      "Train Loss: 0.0895\n",
      "Train F1 Score: 0.9665\n",
      "\n",
      "Epoch 15\n",
      "Train Loss: 0.0892\n",
      "Train F1 Score: 0.9663\n",
      "\n",
      "Epoch 16\n",
      "Train Loss: 0.0960\n",
      "Train F1 Score: 0.9626\n",
      "\n",
      "Epoch 17\n",
      "Train Loss: 0.0774\n",
      "Train F1 Score: 0.9710\n",
      "\n",
      "Epoch 18\n",
      "Train Loss: 0.0824\n",
      "Train F1 Score: 0.9695\n",
      "\n",
      "Epoch 19\n",
      "Train Loss: 0.0727\n",
      "Train F1 Score: 0.9734\n",
      "\n",
      "Epoch 20\n",
      "Train Loss: 0.0612\n",
      "Train F1 Score: 0.9777\n",
      "\n",
      "Epoch 21\n",
      "Train Loss: 0.0805\n",
      "Train F1 Score: 0.9678\n",
      "\n",
      "Epoch 22\n",
      "Train Loss: 0.0731\n",
      "Train F1 Score: 0.9736\n",
      "\n",
      "Epoch 00023: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 23\n",
      "Train Loss: 0.0666\n",
      "Train F1 Score: 0.9757\n",
      "\n",
      "Epoch 24\n",
      "Train Loss: 0.0444\n",
      "Train F1 Score: 0.9827\n",
      "\n",
      "Epoch 25\n",
      "Train Loss: 0.0341\n",
      "Train F1 Score: 0.9874\n",
      "\n",
      "Epoch 26\n",
      "Train Loss: 0.0259\n",
      "Train F1 Score: 0.9900\n",
      "\n",
      "Epoch 27\n",
      "Train Loss: 0.0295\n",
      "Train F1 Score: 0.9890\n",
      "\n",
      "Epoch 28\n",
      "Train Loss: 0.0306\n",
      "Train F1 Score: 0.9896\n",
      "\n",
      "Epoch 29\n",
      "Train Loss: 0.0277\n",
      "Train F1 Score: 0.9906\n",
      "\n",
      "Epoch 30\n",
      "Train Loss: 0.0249\n",
      "Train F1 Score: 0.9907\n",
      "\n",
      "Epoch 31\n",
      "Train Loss: 0.0323\n",
      "Train F1 Score: 0.9884\n",
      "\n",
      "Epoch 32\n",
      "Train Loss: 0.0314\n",
      "Train F1 Score: 0.9894\n",
      "\n",
      "Epoch 00033: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 33\n",
      "Train Loss: 0.0308\n",
      "Train F1 Score: 0.9882\n",
      "\n",
      "Epoch 34\n",
      "Train Loss: 0.0177\n",
      "Train F1 Score: 0.9931\n",
      "\n",
      "Epoch 35\n",
      "Train Loss: 0.0162\n",
      "Train F1 Score: 0.9941\n",
      "\n",
      "Epoch 36\n",
      "Train Loss: 0.0127\n",
      "Train F1 Score: 0.9953\n",
      "\n",
      "Epoch 37\n",
      "Train Loss: 0.0161\n",
      "Train F1 Score: 0.9940\n",
      "\n",
      "Epoch 38\n",
      "Train Loss: 0.0159\n",
      "Train F1 Score: 0.9941\n",
      "\n",
      "Epoch 00039: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Epoch 39\n",
      "Train Loss: 0.0156\n",
      "Train F1 Score: 0.9926\n",
      "\n",
      "Epoch 40\n",
      "Train Loss: 0.0103\n",
      "Train F1 Score: 0.9957\n",
      "\n",
      "Epoch 41\n",
      "Train Loss: 0.0111\n",
      "Train F1 Score: 0.9957\n",
      "\n",
      "Epoch 42\n",
      "Train Loss: 0.0112\n",
      "Train F1 Score: 0.9954\n",
      "\n",
      "Epoch 43\n",
      "Train Loss: 0.0101\n",
      "Train F1 Score: 0.9963\n",
      "\n",
      "Epoch 44\n",
      "Train Loss: 0.0105\n",
      "Train F1 Score: 0.9960\n",
      "\n",
      "Epoch 45\n",
      "Train Loss: 0.0123\n",
      "Train F1 Score: 0.9962\n",
      "\n",
      "Epoch 00046: reducing learning rate of group 0 to 6.2500e-06.\n",
      "Epoch 46\n",
      "Train Loss: 0.0124\n",
      "Train F1 Score: 0.9957\n",
      "\n",
      "Epoch 47\n",
      "Train Loss: 0.0073\n",
      "Train F1 Score: 0.9965\n",
      "\n",
      "Epoch 48\n",
      "Train Loss: 0.0089\n",
      "Train F1 Score: 0.9966\n",
      "\n",
      "Epoch 49\n",
      "Train Loss: 0.0087\n",
      "Train F1 Score: 0.9960\n",
      "\n",
      "Epoch 50\n",
      "Train Loss: 0.0073\n",
      "Train F1 Score: 0.9972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 조기 종료 설정\n",
    "patience = 5  # 개선되지 않는 에포크 수\n",
    "best_f1 = 0   # 최고 F1 스코어\n",
    "early_stopping_counter = 0  # 조기 종료 카운터\n",
    "\n",
    "# 학습률 스케줄러 설정\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "#scheduler = OneCycleLR(optimizer, max_lr=LR, steps_per_epoch=len(trn_loader), epochs=EPOCHS)\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(EPOCHS):\n",
    "    model2.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    text_weight = 1.5  # 특정 클래스에서 텍스트 비중을 높이는 값\n",
    "\n",
    "    for images, text_vectors, targets in trn_loader:\n",
    "        images, text_vectors, targets = images.to(device), text_vectors.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 특정 클래스의 경우 텍스트 비중을 높임\n",
    "        mask = torch.isin(targets, torch.tensor([3, 4, 7, 14], device=device))\n",
    "        text_vectors = torch.where(mask.unsqueeze(1), text_vectors * text_weight, text_vectors)\n",
    "\n",
    "        # 모델에 이미지와 텍스트 벡터를 전달\n",
    "        outputs = model2(images, text_vectors)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    train_loss /= len(trn_loader)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    # Scheduler step을 F1 스코어 기준으로 조정\n",
    "    scheduler.step(train_f1)\n",
    "\n",
    "    # F1 스코어 개선 확인\n",
    "    if train_f1 > best_f1:\n",
    "        best_f1 = train_f1  # 최고 F1 갱신\n",
    "        early_stopping_counter = 0  # 카운터 초기화\n",
    "    else:\n",
    "        early_stopping_counter += 1  # 개선되지 않으면 카운터 증가\n",
    "\n",
    "    # 조기 종료 조건 확인\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(\"Early stopping due to no improvement in F1 score.\")\n",
    "        break  # 학습 중단\n",
    "\n",
    "    # 로그 출력\n",
    "    log = f\"Epoch {epoch + 1}\\nTrain Loss: {train_loss:.4f}\\nTrain F1 Score: {train_f1:.4f}\\n\"\n",
    "    print(log)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5\n",
      "Fold 1, Epoch 1, Validation F1 Score: 0.8339\n",
      "Fold 1, Epoch 2, Validation F1 Score: 0.8997\n",
      "Fold 1, Epoch 3, Validation F1 Score: 0.9254\n",
      "Fold 1, Epoch 4, Validation F1 Score: 0.9372\n",
      "Fold 1, Epoch 5, Validation F1 Score: 0.9396\n",
      "Fold 1, Epoch 6, Validation F1 Score: 0.9488\n",
      "Fold 1, Epoch 7, Validation F1 Score: 0.9490\n",
      "Fold 1, Epoch 8, Validation F1 Score: 0.9513\n",
      "Fold 1, Epoch 9, Validation F1 Score: 0.9544\n",
      "Fold 1, Epoch 10, Validation F1 Score: 0.9567\n",
      "Fold 1, Epoch 11, Validation F1 Score: 0.9668\n",
      "Fold 1, Epoch 12, Validation F1 Score: 0.9666\n",
      "Fold 1, Epoch 13, Validation F1 Score: 0.9624\n",
      "Fold 1, Epoch 14, Validation F1 Score: 0.9799\n",
      "Fold 1, Epoch 15, Validation F1 Score: 0.9778\n",
      "Fold 1, Epoch 16, Validation F1 Score: 0.9882\n",
      "Fold 1, Epoch 17, Validation F1 Score: 0.9838\n",
      "Fold 1, Epoch 18, Validation F1 Score: 0.9816\n",
      "Epoch 00019: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Fold 1, Epoch 19, Validation F1 Score: 0.9817\n",
      "Early stopping in fold 1 due to no improvement in F1 score.\n",
      "Training fold 2/5\n",
      "Fold 2, Epoch 1, Validation F1 Score: 0.8192\n",
      "Fold 2, Epoch 2, Validation F1 Score: 0.9029\n",
      "Fold 2, Epoch 3, Validation F1 Score: 0.9036\n",
      "Fold 2, Epoch 4, Validation F1 Score: 0.9228\n",
      "Fold 2, Epoch 5, Validation F1 Score: 0.9363\n",
      "Fold 2, Epoch 6, Validation F1 Score: 0.9558\n",
      "Fold 2, Epoch 7, Validation F1 Score: 0.9560\n",
      "Fold 2, Epoch 8, Validation F1 Score: 0.9569\n",
      "Fold 2, Epoch 9, Validation F1 Score: 0.9689\n",
      "Fold 2, Epoch 10, Validation F1 Score: 0.9618\n",
      "Fold 2, Epoch 11, Validation F1 Score: 0.9770\n",
      "Fold 2, Epoch 12, Validation F1 Score: 0.9765\n",
      "Fold 2, Epoch 13, Validation F1 Score: 0.9807\n",
      "Fold 2, Epoch 14, Validation F1 Score: 0.9787\n",
      "Fold 2, Epoch 15, Validation F1 Score: 0.9778\n",
      "Fold 2, Epoch 16, Validation F1 Score: 0.9801\n",
      "Early stopping in fold 2 due to no improvement in F1 score.\n",
      "Training fold 3/5\n",
      "Fold 3, Epoch 1, Validation F1 Score: 0.8115\n",
      "Fold 3, Epoch 2, Validation F1 Score: 0.8793\n",
      "Fold 3, Epoch 3, Validation F1 Score: 0.8949\n",
      "Fold 3, Epoch 4, Validation F1 Score: 0.9271\n",
      "Fold 3, Epoch 5, Validation F1 Score: 0.9411\n",
      "Fold 3, Epoch 6, Validation F1 Score: 0.9494\n",
      "Fold 3, Epoch 7, Validation F1 Score: 0.9484\n",
      "Fold 3, Epoch 8, Validation F1 Score: 0.9552\n",
      "Fold 3, Epoch 9, Validation F1 Score: 0.9626\n",
      "Fold 3, Epoch 10, Validation F1 Score: 0.9654\n",
      "Fold 3, Epoch 11, Validation F1 Score: 0.9698\n",
      "Fold 3, Epoch 12, Validation F1 Score: 0.9685\n",
      "Fold 3, Epoch 13, Validation F1 Score: 0.9716\n",
      "Fold 3, Epoch 14, Validation F1 Score: 0.9769\n",
      "Fold 3, Epoch 15, Validation F1 Score: 0.9799\n",
      "Fold 3, Epoch 16, Validation F1 Score: 0.9735\n",
      "Fold 3, Epoch 17, Validation F1 Score: 0.9730\n",
      "Fold 3, Epoch 18, Validation F1 Score: 0.9809\n",
      "Fold 3, Epoch 19, Validation F1 Score: 0.9801\n",
      "Fold 3, Epoch 20, Validation F1 Score: 0.9815\n",
      "Fold 3, Epoch 21, Validation F1 Score: 0.9809\n",
      "Fold 3, Epoch 22, Validation F1 Score: 0.9866\n",
      "Fold 3, Epoch 23, Validation F1 Score: 0.9831\n",
      "Fold 3, Epoch 24, Validation F1 Score: 0.9859\n",
      "Fold 3, Epoch 25, Validation F1 Score: 0.9766\n",
      "Early stopping in fold 3 due to no improvement in F1 score.\n",
      "Training fold 4/5\n",
      "Fold 4, Epoch 1, Validation F1 Score: 0.8198\n",
      "Fold 4, Epoch 2, Validation F1 Score: 0.8707\n",
      "Fold 4, Epoch 3, Validation F1 Score: 0.8973\n",
      "Fold 4, Epoch 4, Validation F1 Score: 0.9236\n",
      "Fold 4, Epoch 5, Validation F1 Score: 0.9375\n",
      "Fold 4, Epoch 6, Validation F1 Score: 0.9421\n",
      "Fold 4, Epoch 7, Validation F1 Score: 0.9497\n",
      "Fold 4, Epoch 8, Validation F1 Score: 0.9437\n",
      "Fold 4, Epoch 9, Validation F1 Score: 0.9626\n",
      "Fold 4, Epoch 10, Validation F1 Score: 0.9720\n",
      "Fold 4, Epoch 11, Validation F1 Score: 0.9636\n",
      "Fold 4, Epoch 12, Validation F1 Score: 0.9720\n",
      "Fold 4, Epoch 13, Validation F1 Score: 0.9697\n",
      "Fold 4, Epoch 14, Validation F1 Score: 0.9749\n",
      "Fold 4, Epoch 15, Validation F1 Score: 0.9756\n",
      "Fold 4, Epoch 16, Validation F1 Score: 0.9792\n",
      "Fold 4, Epoch 17, Validation F1 Score: 0.9823\n",
      "Fold 4, Epoch 18, Validation F1 Score: 0.9763\n",
      "Fold 4, Epoch 19, Validation F1 Score: 0.9810\n",
      "Fold 4, Epoch 20, Validation F1 Score: 0.9787\n",
      "Early stopping in fold 4 due to no improvement in F1 score.\n",
      "Training fold 5/5\n",
      "Fold 5, Epoch 1, Validation F1 Score: 0.8113\n",
      "Fold 5, Epoch 2, Validation F1 Score: 0.8902\n",
      "Fold 5, Epoch 3, Validation F1 Score: 0.9169\n",
      "Fold 5, Epoch 4, Validation F1 Score: 0.9297\n",
      "Fold 5, Epoch 5, Validation F1 Score: 0.9417\n",
      "Fold 5, Epoch 6, Validation F1 Score: 0.9511\n",
      "Fold 5, Epoch 7, Validation F1 Score: 0.9620\n",
      "Fold 5, Epoch 8, Validation F1 Score: 0.9581\n",
      "Fold 5, Epoch 9, Validation F1 Score: 0.9673\n",
      "Fold 5, Epoch 10, Validation F1 Score: 0.9778\n",
      "Fold 5, Epoch 11, Validation F1 Score: 0.9763\n",
      "Fold 5, Epoch 12, Validation F1 Score: 0.9715\n",
      "Fold 5, Epoch 13, Validation F1 Score: 0.9772\n",
      "Early stopping in fold 5 due to no improvement in F1 score.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Prediction 저장소 초기화\n",
    "fold_predictions = []\n",
    "\n",
    "# K-Fold 설정\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(trn_dataset.df, trn_dataset.df['target'])):\n",
    "    print(f\"Training fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    # Train/Validation Subset 생성\n",
    "    train_subset = Subset(trn_dataset, train_idx)\n",
    "    val_subset = Subset(trn_dataset, val_idx)\n",
    "    \n",
    "    # DataLoader 정의\n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=False, drop_last=False)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=False)\n",
    "\n",
    "    # 모델 초기화\n",
    "    model = MultimodalModel(\n",
    "        model_name=model_name,\n",
    "        text_dim=50,  # 텍스트 벡터의 차원\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "    \n",
    "    # 학습 루프\n",
    "    patience = 3\n",
    "    early_stopping_counter = 0\n",
    "    fold_best_f1 = 0\n",
    "    text_weight = 1.5  # 특정 클래스에서 텍스트 비중을 높이는 값\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        preds_list = []\n",
    "        targets_list = []\n",
    "        \n",
    "        for images, text_vectors, targets in train_loader:\n",
    "            images, text_vectors, targets = images.to(device), text_vectors.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 특정 클래스의 경우 텍스트 비중을 높임\n",
    "            mask = torch.isin(targets, torch.tensor([3, 4, 7, 14], device=device))\n",
    "            text_vectors = torch.where(mask.unsqueeze(1), text_vectors * text_weight, text_vectors)\n",
    "\n",
    "            # 모델에 이미지와 텍스트 벡터를 전달\n",
    "            outputs = model(images, text_vectors)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            preds_list.extend(outputs.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "        \n",
    "        # 학습률 스케줄러 적용\n",
    "        scheduler.step(train_f1)\n",
    "        \n",
    "        # Validation Step\n",
    "        model.eval()\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, text_vectors, targets in val_loader:\n",
    "                images, text_vectors, targets = images.to(device), text_vectors.to(device), targets.to(device)\n",
    "                preds = model(images, text_vectors)\n",
    "                val_preds.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "                val_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        val_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1}, Validation F1 Score: {val_f1:.4f}\")\n",
    "        \n",
    "        # Best F1 Score 업데이트 및 조기 종료 체크\n",
    "        if val_f1 > fold_best_f1:\n",
    "            fold_best_f1 = val_f1\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "        \n",
    "        if early_stopping_counter >= patience:\n",
    "            print(f\"Early stopping in fold {fold + 1} due to no improvement in F1 score.\")\n",
    "            break\n",
    "\n",
    "    # 폴드별 예측 저장\n",
    "    fold_predictions.append((val_targets, val_preds))\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:23<00:00,  4.22it/s]\n"
     ]
    }
   ],
   "source": [
    "preds_list = []\n",
    "\n",
    "model.eval()\n",
    "for image, _, _ in tqdm(tst_loader):   # tst_loader에서는 image와 target만 반환\n",
    "    image = image.to(device)\n",
    "\n",
    "    # 더미 텍스트 벡터 생성 (예: 크기 50의 제로 텐서)\n",
    "    text = torch.zeros((image.size(0), 50)).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image, text)  # 더미 텍스트 벡터도 함께 전달\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:23<00:00,  4.25it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "preds_list = []\n",
    "\n",
    "model2.eval()\n",
    "for image, _, _ in tqdm(tst_loader):   # tst_loader에서는 image와 target만 반환\n",
    "    image = image.to(device)\n",
    "\n",
    "    # 더미 텍스트 벡터 생성 (예: 크기 50의 제로 텐서)\n",
    "    text = torch.zeros((image.size(0), 50)).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model2(image, text)  # 더미 텍스트 벡터도 함께 전달\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1700315216829,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "aClN7Qi7VZoh"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315238836,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "VDBXQqAzVvLY"
   },
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"/root/data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1700315244710,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "ePx2vCELVnuS"
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"/root/data/output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3771: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8464: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.4878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0558: 100%|██████████| 40/40 [00:12<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.5407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8217: 100%|██████████| 40/40 [00:12<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5758: 100%|██████████| 40/40 [00:12<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.6941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3068: 100%|██████████| 40/40 [00:12<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.7785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0804: 100%|██████████| 40/40 [00:12<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.7505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9699: 100%|██████████| 40/40 [00:12<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0525: 100%|██████████| 40/40 [00:13<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.8155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0145: 100%|██████████| 40/40 [00:12<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1 Score: 0.8386\n",
      "Class 0: F1 Score = 0.9565\n",
      "Class 1: F1 Score = 0.9091\n",
      "Class 2: F1 Score = 0.9697\n",
      "Class 3: F1 Score = 0.3333\n",
      "Class 4: F1 Score = 0.7000\n",
      "Class 5: F1 Score = 0.9474\n",
      "Class 6: F1 Score = 0.9545\n",
      "Class 7: F1 Score = 0.4255\n",
      "Class 8: F1 Score = 1.0000\n",
      "Class 9: F1 Score = 0.9744\n",
      "Class 10: F1 Score = 0.9189\n",
      "Class 11: F1 Score = 0.8800\n",
      "Class 12: F1 Score = 0.9167\n",
      "Class 13: F1 Score = 0.8936\n",
      "Class 14: F1 Score = 0.4762\n",
      "Class 15: F1 Score = 1.0000\n",
      "Class 16: F1 Score = 1.0000\n",
      "\n",
      "Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 3.5005: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.3571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8983: 100%|██████████| 40/40 [00:12<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0775: 100%|██████████| 40/40 [00:12<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.5824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8866: 100%|██████████| 40/40 [00:12<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.6404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5532: 100%|██████████| 40/40 [00:12<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.7259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1546: 100%|██████████| 40/40 [00:12<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.7246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3088: 100%|██████████| 40/40 [00:13<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.7604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6479: 100%|██████████| 40/40 [00:12<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.7987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7792: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2005: 100%|██████████| 40/40 [00:12<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 F1 Score: 0.8258\n",
      "Class 0: F1 Score = 0.9474\n",
      "Class 1: F1 Score = 0.8780\n",
      "Class 2: F1 Score = 1.0000\n",
      "Class 3: F1 Score = 0.5500\n",
      "Class 4: F1 Score = 0.7500\n",
      "Class 5: F1 Score = 1.0000\n",
      "Class 6: F1 Score = 0.8276\n",
      "Class 7: F1 Score = 0.2857\n",
      "Class 8: F1 Score = 1.0000\n",
      "Class 9: F1 Score = 1.0000\n",
      "Class 10: F1 Score = 0.7568\n",
      "Class 11: F1 Score = 0.7692\n",
      "Class 12: F1 Score = 0.8667\n",
      "Class 13: F1 Score = 0.8511\n",
      "Class 14: F1 Score = 0.5926\n",
      "Class 15: F1 Score = 0.9630\n",
      "Class 16: F1 Score = 1.0000\n",
      "\n",
      "Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4066: 100%|██████████| 40/40 [00:12<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9028: 100%|██████████| 40/40 [00:13<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.4378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9840: 100%|██████████| 40/40 [00:13<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.5255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6111: 100%|██████████| 40/40 [00:12<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3577: 100%|██████████| 40/40 [00:12<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.6965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5623: 100%|██████████| 40/40 [00:12<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.7278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8190: 100%|██████████| 40/40 [00:13<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.7367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2689: 100%|██████████| 40/40 [00:12<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.7899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1302: 100%|██████████| 40/40 [00:12<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.8169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8996: 100%|██████████| 40/40 [00:12<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 F1 Score: 0.8462\n",
      "Class 0: F1 Score = 1.0000\n",
      "Class 1: F1 Score = 0.8333\n",
      "Class 2: F1 Score = 1.0000\n",
      "Class 3: F1 Score = 0.4000\n",
      "Class 4: F1 Score = 0.5957\n",
      "Class 5: F1 Score = 1.0000\n",
      "Class 6: F1 Score = 0.9744\n",
      "Class 7: F1 Score = 0.5000\n",
      "Class 8: F1 Score = 1.0000\n",
      "Class 9: F1 Score = 1.0000\n",
      "Class 10: F1 Score = 0.9412\n",
      "Class 11: F1 Score = 0.9412\n",
      "Class 12: F1 Score = 0.8000\n",
      "Class 13: F1 Score = 0.9444\n",
      "Class 14: F1 Score = 0.5000\n",
      "Class 15: F1 Score = 0.9545\n",
      "Class 16: F1 Score = 1.0000\n",
      "\n",
      "Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3049: 100%|██████████| 40/40 [00:12<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.3294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2671: 100%|██████████| 40/40 [00:12<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.4805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7305: 100%|██████████| 40/40 [00:13<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6904: 100%|██████████| 40/40 [00:12<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8003: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.6318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8578: 100%|██████████| 40/40 [00:12<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.7366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0042: 100%|██████████| 40/40 [00:12<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2207: 100%|██████████| 40/40 [00:12<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.7848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0536: 100%|██████████| 40/40 [00:12<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.7909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9198: 100%|██████████| 40/40 [00:12<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 F1 Score: 0.8156\n",
      "Class 0: F1 Score = 0.9524\n",
      "Class 1: F1 Score = 0.9000\n",
      "Class 2: F1 Score = 1.0000\n",
      "Class 3: F1 Score = 0.5455\n",
      "Class 4: F1 Score = 0.5306\n",
      "Class 5: F1 Score = 0.9583\n",
      "Class 6: F1 Score = 1.0000\n",
      "Class 7: F1 Score = 0.4211\n",
      "Class 8: F1 Score = 0.9091\n",
      "Class 9: F1 Score = 0.9268\n",
      "Class 10: F1 Score = 0.8571\n",
      "Class 11: F1 Score = 0.8649\n",
      "Class 12: F1 Score = 0.8837\n",
      "Class 13: F1 Score = 0.9333\n",
      "Class 14: F1 Score = 0.2400\n",
      "Class 15: F1 Score = 0.9655\n",
      "Class 16: F1 Score = 0.9767\n",
      "\n",
      "Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.6057: 100%|██████████| 40/40 [00:12<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2695: 100%|██████████| 40/40 [00:12<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.4876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7978: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4890: 100%|██████████| 40/40 [00:12<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.6588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5093: 100%|██████████| 40/40 [00:12<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.7303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7311: 100%|██████████| 40/40 [00:12<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.7246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0621: 100%|██████████| 40/40 [00:12<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5857: 100%|██████████| 40/40 [00:12<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9272: 100%|██████████| 40/40 [00:12<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.8131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3711: 100%|██████████| 40/40 [00:12<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 F1 Score: 0.8204\n",
      "Class 0: F1 Score = 1.0000\n",
      "Class 1: F1 Score = 0.9302\n",
      "Class 2: F1 Score = 1.0000\n",
      "Class 3: F1 Score = 0.4103\n",
      "Class 4: F1 Score = 0.5366\n",
      "Class 5: F1 Score = 1.0000\n",
      "Class 6: F1 Score = 1.0000\n",
      "Class 7: F1 Score = 0.4444\n",
      "Class 8: F1 Score = 0.9412\n",
      "Class 9: F1 Score = 0.9615\n",
      "Class 10: F1 Score = 0.8205\n",
      "Class 11: F1 Score = 0.9796\n",
      "Class 12: F1 Score = 0.6897\n",
      "Class 13: F1 Score = 0.8511\n",
      "Class 14: F1 Score = 0.4118\n",
      "Class 15: F1 Score = 0.9697\n",
      "Class 16: F1 Score = 1.0000\n",
      "\n",
      "Class-wise Average F1 Scores:\n",
      "Class 0: Average F1 Score = 0.9713\n",
      "Class 1: Average F1 Score = 0.8901\n",
      "Class 2: Average F1 Score = 0.9939\n",
      "Class 3: Average F1 Score = 0.4478\n",
      "Class 4: Average F1 Score = 0.6226\n",
      "Class 5: Average F1 Score = 0.9811\n",
      "Class 6: Average F1 Score = 0.9513\n",
      "Class 7: Average F1 Score = 0.4153\n",
      "Class 8: Average F1 Score = 0.9701\n",
      "Class 9: Average F1 Score = 0.9725\n",
      "Class 10: Average F1 Score = 0.8589\n",
      "Class 11: Average F1 Score = 0.8870\n",
      "Class 12: Average F1 Score = 0.8313\n",
      "Class 13: Average F1 Score = 0.8947\n",
      "Class 14: Average F1 Score = 0.4441\n",
      "Class 15: Average F1 Score = 0.9705\n",
      "Class 16: Average F1 Score = 0.9953\n"
     ]
    }
   ],
   "source": [
    "#추가 검증 : class마다 f1 score 구해서 낮은 f1 끌어올려보기 \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "# 데이터 불러오기\n",
    "data_path = '/root/data/train.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "n_splits = 5  # K-Fold split 수 설정\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# K-Fold 설정\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "# 클래스별 F1 스코어를 저장할 딕셔너리\n",
    "class_f1_scores = defaultdict(list)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['target'])):\n",
    "    print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "    \n",
    "    # Train/Validation 데이터 분리\n",
    "    train_subset = Subset(trn_dataset, train_idx)\n",
    "    val_subset = Subset(trn_dataset, val_idx)\n",
    "    \n",
    "    # DataLoader 정의\n",
    "    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    # 모델 초기화\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # 학습 루프\n",
    "    best_f1 = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_one_epoch(train_loader, model, optimizer, loss_fn, device=device)\n",
    "        \n",
    "        # 검증 루프\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "                preds = model(images)\n",
    "                val_preds.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "                val_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        # Fold F1 스코어 계산\n",
    "        fold_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "        print(f\"Fold {fold + 1} F1 Score: {fold_f1:.4f}\")\n",
    "        \n",
    "        if fold_f1 > best_f1:\n",
    "            best_f1 = fold_f1\n",
    "\n",
    "    # 클래스별 F1 스코어 계산\n",
    "    class_report = classification_report(val_targets, val_preds, output_dict=True)\n",
    "    for class_id in range(17):\n",
    "        f1_score_class = class_report[str(class_id)]['f1-score']\n",
    "        class_f1_scores[class_id].append(f1_score_class)\n",
    "        print(f\"Class {class_id}: F1 Score = {f1_score_class:.4f}\")\n",
    "\n",
    "# 클래스별 평균 F1 스코어 출력\n",
    "print(\"\\nClass-wise Average F1 Scores:\")\n",
    "for class_id, scores in class_f1_scores.items():\n",
    "    avg_f1_score = np.mean(scores)\n",
    "    print(f\"Class {class_id}: Average F1 Score = {avg_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class 3,7,14 f1 score 너무 낮음 + 4 도 추가로 보면 좋을것\n",
    "3,confirmation_of_admission_and_discharge\n",
    "7,medical_outpatient_certificate\n",
    "14,statement_of_opinion\n",
    "\n",
    "4,diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#메모리 초기화\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
